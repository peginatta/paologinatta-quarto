{
  "hash": "5ed7cc14c53c3aaf3ff9d01122eb2251",
  "result": {
    "markdown": "---\ntitle: \"A guide to correctly calculating posterior predictions and average marginal effects with multilievel Bayesian models\"\ndate: 2021-11-10\ndescription: \"How to calculate grand means, conditional group means, and hypothetical group means of posterior predictions from multilevel brms models.\"\nimage: index_files/figure-html/all-effects-combined-1.png\ncategories:\n  - r\n  - tidyverse\n  - regression\n  - statistics\n  - data visualization\n  - bayes\n  - brms\n  - stan\n  - beta\nformat:\n  html:\n    toc-depth: 4\ndoi: 10.59350/wbn93-edb02\ncitation: true\n---\n\n\n\n\n[At the end](https://www.andrewheiss.com/blog/2021/11/08/beta-regression-guide/#super-fancy-detailed-model-with-lots-of-moving-parts-just-for-fun) of my [previous post on beta and zero-inflated-beta regression](https://www.andrewheiss.com/blog/2021/11/08/beta-regression-guide/), I included an example of a multilevel model that predicted the proportion of women members of parliament based on whether a country implements gender-based quotas for their legislatures, along with a few different control variables. I also included random effects for year and region in order to capture time- and geography-specific trends. When interpreting the results, I naively said that calculating posterior predictions from the model (i.e. plugging arbitrary values into the model and finding the predicted value of the outcome) magically and automatically includes information about year and region (or the random effects included in the model). But I was wrong-ish! Incorporating information about the random effects of a multilevel model is actually a lot more involved and detailed than I thought, and the nuances are really important and make a big difference!\n\nAs [TJ Mahr recently tweeted](https://twitter.com/tjmahr/status/1450486103497187328?s=21), this is hard stuff!\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](tj-tweet.png){fig-align='center' width=90%}\n:::\n:::\n\n\nFortunately, over the past couple days I've been part of several really long Twitter threads (with people who know waaaay more about this than me!) about different ways of incorporating group-level effects into posterior predictions. HUGE THANKS to [Isabella Ghement](https://twitter.com/IsabellaGhement), [Brenton Wiernik](https://twitter.com/bmwiernik), [TJ Mahr](https://twitter.com/tjmahr), [Donald Williams](https://twitter.com/wdonald_1985), [Solomon Kurz](https://twitter.com/SolomonKurz), and [Mattan Ben-Shachar](https://twitter.com/mattansb) for all their help and tweeting! ([This set of tweets by Brenton](https://twitter.com/bmwiernik/status/1458043604128215040) was pivotal!)\n\n\n## Who this guide is for\n\nTo borrow from [Solomon Kurz](https://solomonkurz.netlify.app/post/2021-09-22-sexy-up-your-logistic-regression-model-with-logit-dotplots/), here's what this guide assumes you know:\n\n- You're familiar with [R](https://www.r-project.org/) and the [tidyverse](https://www.tidyverse.org/) (particularly [dplyr](https://dplyr.tidyverse.org/) and [ggplot2](https://ggplot2.tidyverse.org/)).\n- You're familiar with [brms](https://paul-buerkner.github.io/brms/) for running Bayesian regression models. See [the vignettes here](https://paul-buerkner.github.io/brms/articles/index.html), examples like [this](https://www.rensvandeschoot.com/tutorials/brms-started/), or [resources like these](https://evalf21.classes.andrewheiss.com/resource/bayes/#resources) for an introduction.\n- You're somewhat familiar with multilevel models. [Confusingly](https://twitter.com/chelseaparlett/status/1458461737431146500), these are also called mixed effect models, random effect models, and hierarchical models, among others! They're all the same thing! (<small>image below by [Chelsea Parlett-Pelleriti](https://twitter.com/chelseaparlett/status/1458461737431146500)</small>)\n\n\n  ::: {.cell layout-align=\"center\"}\n  ::: {.cell-output-display}\n  ![](chelsea-meme.jpg){fig-align='center' width=60%}\n  :::\n  :::\n\n\n    See examples like [this](https://www.tjmahr.com/plotting-partial-pooling-in-mixed-effects-models/) or [this](https://www.tjmahr.com/another-mixed-effects-model-visualization/) or [this](https://www.rensvandeschoot.com/tutorials/lme4/) or [this](https://rstudio-pubs-static.s3.amazonaws.com/63556_e35cc7e2dfb54a5bb551f3fa4b3ec4ae.html). Basically Google \"lme4 example\" (lme4 is what you use for frequentist, non-Bayesian multilevel models with R) or \"brms multilevel example\" and you'll find a bunch. For a more formal treatment, see chapter 12 in [Richard McElreath's *Statistcal Rethinking*](https://xcelab.net/rm/statistical-rethinking/) book (or [this R translation of it](https://bookdown.org/content/3890/multilevel-models.html) by Solomon Kurz).\n\n\n## Example data\n\nPut simply, multilevel models let you account for nested structures in data: \n\n- Students inside schools inside school districts inside states\n- Study participants inside cities inside states across months\n- Countries within regions and across years\n\nSince most of my own work deals with international politics, we'll use an example with countries and years. We'll use data from the [Varieties of Democracy project (V-Dem)](https://www.v-dem.net/en/) to explore the relationship between press freedom and the degree to which political opposition is allowed. Is there more press freedom in countries that allow opposition parties?\n\nThere's [a great R package for accessing V-Dem data](https://github.com/vdeminstitute/vdemdata) without needing to download it manually from their website, so we'll use that to make a smaller dataset of countries for just 2015. Let's load all the libraries we need, clean up the data, and get started!\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)    # ggplot, dplyr, %>%, and friends\nlibrary(brms)         # Bayesian modeling through Stan\nlibrary(tidybayes)    # Manipulate Stan objects in a tidy way\nlibrary(broom)        # Convert model objects to data frames\nlibrary(broom.mixed)  # Convert brms model objects to data frames\nlibrary(emmeans)      # Calculate marginal effects in even fancier ways\nlibrary(vdemdata)     # Use data from the Varieties of Democracy (V-Dem) project\nlibrary(patchwork)    # Combine ggplot objects\nlibrary(ggokabeito)   # Neat accessible color palette\nlibrary(gghalves)     # Special half geoms\nlibrary(ggbeeswarm)   # Special distribution-shaped point jittering\n\n# Custom ggplot theme to make pretty plots\n# Get the News Cycle font at https://fonts.google.com/specimen/News+Cycle\ntheme_clean <- function() {\n  theme_minimal(base_family = \"News Cycle\") +\n    theme(panel.grid.minor = element_blank(),\n          plot.title = element_text(face = \"bold\"),\n          axis.title = element_text(face = \"bold\"),\n          strip.text = element_text(face = \"bold\", size = rel(1), hjust = 0),\n          strip.background = element_rect(fill = \"grey80\", color = NA),\n          legend.title = element_text(face = \"bold\"))\n}\n```\n:::\n\n\nV-Dem includes hundreds of different variables, but we only need a few, and we'll make a few adjustments to the ones we do need. Here's what we'll do:\n\n- **Main outcome**: Alternative sources of information index (`v2xme_altinf` in V-Dem). This is a 0–1 scale that measures…\n\n  > To what extent the [is] media (a) un-biased in their coverage or lack of coverage of the opposition, (b) allowed to be critical of the regime, and (c) representative of a wide array of political perspectives\n  \n  Higher values represent more media freedom.\n\n- **Main binary explanatory variable**: Opposition parties autonomy (`v2psoppaut` in V-Dem). This is an ordinal variable with these possible values:\n\n  > - 0: Opposition parties are not allowed.\n  > - 1: There are no autonomous, independent opposition parties. Opposition parties are either selected or co-opted by the ruling regime.\n  > - 2: At least some opposition parties are autonomous and independent of the ruling regime.\n  > - 3: Most significant opposition parties are autonomous and independent of the ruling regime.\n  > - 4: All opposition parties are autonomous and independent of the ruling regime.\n  \n  For the sake of simplicity, we'll collapse this into a binary variable. Parties are autonomous if they score a 3 or a 4; they're not autonomous if they score a 0, 1, or 2. Also, there are a handful of countries (Saudi Arabia, Qatar, etc.) with missing data for this column, since they don't have *any* opposition parties. We'll treat them as not-autonomous here.\n\n- **Main continuous explanatory variable**: Civil liberties index (`v2x_civlib`). This is a continuous variable measured from 0–1 with higher values representing better respect for human rights and civil liberties.\n\n- **Grouping**: Finally, we'll use region as groups in these models (i.e. countries nested in regions). V-Dem provides multiple regional variables with varying specificity (19 different regions, 10 different regions, and 6 different regions). We'll use the 6-region version (`e_regionpol_6C`) for simplicity here:\n\n  > - 1: Eastern Europe and Central Asia (including Mongolia)\n  > - 2: Latin America and the Caribbean\n  > - 3: The Middle East and North Africa (including Israel and Turkey, excluding Cyprus)\n  > - 4: Sub-Saharan Africa\n  > - 5: Western Europe and North America (including Cyprus, Australia and New Zealand)\n  > - 6: Asia and Pacific (excluding Australia and New Zealand)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Make a subset of the full V-Dem data\nvdem_2015 <- vdem %>% \n  select(country_name, country_text_id, year, region = e_regionpol_6C,\n         media_index = v2xme_altinf, party_autonomy_ord = v2psoppaut_ord,\n         polyarchy = v2x_polyarchy, civil_liberties = v2x_civlib) %>% \n  filter(year == 2015) %>% \n  mutate(party_autonomy = party_autonomy_ord >= 3,\n         party_autonomy = ifelse(is.na(party_autonomy), FALSE, party_autonomy)) %>% \n  mutate(region = factor(region, \n                         labels = c(\"Eastern Europe and Central Asia\",\n                                    \"Latin America and the Caribbean\",\n                                    \"Middle East and North Africa\",\n                                    \"Sub-Saharan Africa\",\n                                    \"Western Europe and North America\",\n                                    \"Asia and Pacific\")))\n```\n:::\n\n\n## Explore the data\n\nWe're interested in a couple relationships here. First, we want to know if there is more press freedom in countries that allow opposition parties in elections. Let's look at the data really quick:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautonomy_halves <- ggplot(vdem_2015, aes(x = party_autonomy, y = media_index)) +\n  geom_half_point(aes(color = party_autonomy), \n                  transformation = position_quasirandom(width = 0.1),\n                  side = \"l\", size = 0.5, alpha = 0.5) +\n  geom_half_boxplot(aes(fill = party_autonomy), side = \"r\") + \n  scale_fill_okabe_ito() +\n  scale_color_okabe_ito() +\n  guides(color = \"none\", fill = \"none\") +\n  labs(x = \"Opposition party autonomy\", y = \"Media freedom index\") +\n  theme_clean()\n\nautonomy_densities <- ggplot(vdem_2015, aes(x = media_index, fill = party_autonomy)) +\n  geom_density(alpha = 0.6) +\n  scale_fill_okabe_ito() +\n  labs(x = \"Media freedom index\", y = \"Density\", fill = \"Opposition party autonomy\") +\n  theme_clean() +\n  theme(legend.position = \"bottom\")\n\nautonomy_halves | autonomy_densities\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot-explore-autonomy-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\nThat confirms our initial suspicions: countries that do not allow opposition parties to participate in elections tend to have substantially lower media freedom index scores than countries that have opposition parties.\n\nLet's see how respect for civil liberties is related to media freedom:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(vdem_2015, aes(x = civil_liberties, y = media_index)) +\n  geom_point(aes(color = region)) +\n  geom_smooth(method = \"lm\") +\n  labs(x = \"Civil liberties index\", y = \"Media freedom index\",\n       color = \"Region\") +\n  scale_color_okabe_ito() +\n  theme_clean()\n## `geom_smooth()` using formula = 'y ~ x'\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\nCountries with greater respect for civil liberties and human rights tend to have higher values of media freedom. There are perhaps some regional trends here too—most of the countries in Western Europe and North America are clustered in the top right corner of the plot, but all other regions are spread throughout.\n\n\n## Model\n\nLet's make a model! We'll look just at 2015 data to estimate the effect of party autonomy (a binary variable) and civil liberties (a continuous variable) on a country's media freedom index. We'll include random effects for region, assuming that there are regional differences in this relationship (i.e. the relationship between party autonomy and media freedom looks different in Asia from Western Europe).\n\nBecause `media_index` ranges from 0 to 1 but does not include 0 or 1, we'll use a beta distribution. It's [a really neat and fun distribution to work with](https://www.andrewheiss.com/blog/2021/11/08/beta-regression-guide/), and it has extra moving parts we can play with—we can model the $\\phi$ parameter (or the precision/variance of the distribution) with random effects too.\n\nFormally, we can define the full model like this:\n\n$$\n\\begin{aligned}\n&\\text{[likelihood]} \\\\\n\\text{Media freedom index}_i &\\sim \\operatorname{Beta}(\\mu_i, \\phi_i) \\\\\n\\ \\\\\n&\\text{[} \\mu \\text{ part of beta distribution]} \\\\\n\\operatorname{logit}(\\mu_i) &= \\alpha_{j[i]} + \\beta_1 \\text{Party autonomy}_i + \\beta_2 \\text{Civil liberties}_i\\\\\n\\ \\\\\n&\\text{[} \\phi \\text{ part of beta distribution]} \\\\\n\\log(\\phi_i) &= \\alpha_{j[i]}\\\\\n\\ \\\\\n& \\text{[region-specific intercepts]} \\\\\n\\alpha_{j} &\\sim \\mathcal{N}(\\mu_{\\alpha_j}, \\sigma^2_{\\alpha_j}), \\text{ for region } j \\text{ in } 1 .. J\n\\end{aligned}\n$$\n\nWe'll model the $\\mu$ (or mean) parameter of the beta distribution with `party_autonomy`, `civil_liberties`, and random intercepts for region, and we'll model the $\\phi$ part (or precision) with just random intercepts for region (though we could use whatever, too—[see this for an explanation of what this parameter does](https://www.andrewheiss.com/blog/2021/11/08/beta-regression-guide/#working-with-the-precision-parameter)).\n\nThe syntax for defining random effects can get complex, depending on if the effects are nested or crossed, and if slopes get involved. [This table by Ben Bolker](https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#model-specification) is *indispensable* for remembering how to define which kinds of effects. Here we're just adding a random intercept for region, so we'll use a `(1 | region)` term in the model code.\n\n\n::: {.cell layout-align=\"center\" hash='index_cache/html/run-model-2015_7b8addb40e98384e4582460db18880d5'}\n\n```{.r .cell-code}\nmodel_basic <- brm(\n  bf(media_index ~ party_autonomy + civil_liberties + (1 | region),\n     phi ~ (1 | region)),\n  data = vdem_2015,\n  family = Beta(),\n  control = list(adapt_delta = 0.9),\n  chains = 4, iter = 2000, warmup = 1000,\n  cores = 4, seed = 12345,\n  # Use the cmdstanr backend for Stan because it's faster and more modern than\n  # the default rstan. You need to install the cmdstanr package first\n  # (https://mc-stan.org/cmdstanr/) and then run cmdstanr::install_cmdstan() to\n  # install cmdstan on your computer.\n  backend = \"cmdstanr\"\n)\n## Start sampling\n## Warning: 1 of 4000 (0.0%) transitions ended with a divergence.\n## See https://mc-stan.org/misc/warnings for details.\n```\n:::\n\n\n\n## Posterior predictions\n\nBecause this model uses beta regression, the coefficients for the $\\mu$ part are on the logit (log odds) scale, while the coefficients for the $\\phi$ part are on the log scale. This makes them really hard to interpret when just looking at a table of coefficient estimates, like this one here:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntidy(model_basic)\n## # A tibble: 6 × 8\n##   effect   component group  term                estimate std.error conf.low conf.high\n##   <chr>    <chr>     <chr>  <chr>                  <dbl>     <dbl>    <dbl>     <dbl>\n## 1 fixed    cond      <NA>   (Intercept)           -2.46      0.302   -3.04      -1.87\n## 2 fixed    cond      <NA>   phi_(Intercept)        2.35      0.474    1.35       3.22\n## 3 fixed    cond      <NA>   party_autonomyTRUE     1.03      0.172    0.698      1.38\n## 4 fixed    cond      <NA>   civil_liberties        3.51      0.316    2.90       4.12\n## 5 ran_pars cond      region sd__(Intercept)        0.499     0.256    0.211      1.19\n## 6 ran_pars cond      region sd__phi_(Intercept)    0.925     0.451    0.365      2.06\n```\n:::\n\n\nEven if we back-transform the estimates to the response scale (with `plogis()` for the logits and `exp()` for the logs), **we still cannot interpret the coefficients directly**. Unlike regular OLS-like regression models, we can't say things like \"a one-unit increase in `party_autonomy` is associated with a `plogis(2.27)` unit increase in `media_freedom`\"—we have to incorporate the intercept and all the other model parameters in order to make marginal interpretations like that.\n\nIn this case, we *are* interested in these marginal effects, though. What is the effect of flipping `party_autonomy` from `FALSE` to `TRUE`? What is the effect of a one-unit increase in the respect for human rights and civil liberties measured by `civil_liberties`? You can't easily figure it out with the raw results of the model because there are so many moving parts: the different pieces (intercept, other coefficients) for the $\\mu$ part need to be combined, the precision parameter $\\phi$ needs to be incorporated somehow, and random regional effects for both the $\\mu$ *and* the $\\phi$ parts need to be accounted for. That's a mess.\n\nInstead of trying to algebraically piece all this together, we can plug hypothetical data into the model's posterior distribution and generate posterior predictions of our media freedom outcome. \n\n### Draws from the posterior predictive distribution\n\nThere are a few general approaches to generating posterior predictions with **brms**. First, we can use `posterior_predict()` to plug a new dataset into the model. As an example, we'll create a little dataset where `party_autonomy` is both `TRUE` and `FALSE`, and we'll arbitrarily set `civil_liberties` to 0.5 (right in the middle of its range) and `region` to the Middle East and North Africa. We'll then plug that in to the model and generate predictions\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnewdata <- expand_grid(party_autonomy = c(TRUE, FALSE),\n                       civil_liberties = c(0.5),\n                       region = \"Middle East and North Africa\")\nnewdata\n## # A tibble: 2 × 3\n##   party_autonomy civil_liberties region                      \n##   <lgl>                    <dbl> <chr>                       \n## 1 TRUE                       0.5 Middle East and North Africa\n## 2 FALSE                      0.5 Middle East and North Africa\n\nposterior_predict(model_basic, newdata) %>% head()\n##       [,1]  [,2]\n## [1,] 0.894 0.401\n## [2,] 0.400 0.751\n## [3,] 0.864 0.476\n## [4,] 0.374 0.332\n## [5,] 0.544 0.495\n## [6,] 0.564 0.596\n```\n:::\n\n\nThis returns a matrix with 4,000 rows and 2 columns—a column for when `party_autonomy` is `TRUE` and one for when it is `FALSE`. This format isn't in the nicest shape for plotting and doing tidy type of stuff with, so we can alternatively use `predicted_draws()` from the **tidybayes** package. This is really just a fancy wrapper around `brms::posterior_predict()` that returns a much nicer tidier data frame:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntidy_pred <- model_basic %>% \n  predicted_draws(newdata = newdata)\ntidy_pred\n## # A tibble: 8,000 × 8\n## # Groups:   party_autonomy, civil_liberties, region, .row [2]\n##    party_autonomy civil_liberties region          .row .chain .iteration .draw .prediction\n##    <lgl>                    <dbl> <chr>          <int>  <int>      <int> <int>       <dbl>\n##  1 TRUE                       0.5 Middle East a…     1     NA         NA     1       0.669\n##  2 TRUE                       0.5 Middle East a…     1     NA         NA     2       0.811\n##  3 TRUE                       0.5 Middle East a…     1     NA         NA     3       0.378\n##  4 TRUE                       0.5 Middle East a…     1     NA         NA     4       0.329\n##  5 TRUE                       0.5 Middle East a…     1     NA         NA     5       0.559\n##  6 TRUE                       0.5 Middle East a…     1     NA         NA     6       0.518\n##  7 TRUE                       0.5 Middle East a…     1     NA         NA     7       0.927\n##  8 TRUE                       0.5 Middle East a…     1     NA         NA     8       0.823\n##  9 TRUE                       0.5 Middle East a…     1     NA         NA     9       0.475\n## 10 TRUE                       0.5 Middle East a…     1     NA         NA    10       0.802\n## # ℹ 7,990 more rows\n```\n:::\n\n\n*That's* much nicer to work with!\n\n### Expected values of the posterior predictive distribution\n\nWe don't necessarily want to use these predicted draws when thinking about marginal effects of coefficients, though. When we use `posterior_predict()`/`predicted_draws()` here, **brms** accounts for the uncertainty of all these things:\n\n- The uncertainty of the fixed coefficients (e.g., `party_autonomy` and `civil_liberties`)\n- The uncertainty of the variance parameters of the groups (e.g., `sd__phi_(Intercept)` for each region)\n- The uncertainty for each individual observation (e.g., observational-level residual variance)\n\nWhen thinking about marginal effects, though, we're more interested in the *expected value* of the outcome, which means we're more focused on the uncertainty in the model parameters and not necessarily the individual-level residuals ([See this post](https://discourse.mc-stan.org/t/difference-between-method-fitted-vs-predict-in-marginal-effects-function/6901/3) or [this discussion](https://github.com/paul-buerkner/brms/issues/82#issuecomment-231440994) for an explanation of the difference between the two types of predictions). To get these expected values, we can use `brms::posterior_epred()` (or the nicer `tidybayes::epred_draws()`), which accounts for the uncertainty of just these two things:\n\n- The uncertainty of the fixed coefficients (e.g., `party_autonomy` and `civil_liberties`)\n- The uncertainty of the variance parameters of the groups (e.g., `sd__phi_(Intercept)` for each region)\n\nThe averages of these draws that are generated by regular `posterior_predict()` and `posterior_epred()` should be generally the same, but the variance for *expected* values will be smaller (since we're not dealing with individual observation-level variance).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Expected values with brms\nposterior_epred(model_basic, newdata) %>% head()\n##       [,1]  [,2]\n## [1,] 0.677 0.413\n## [2,] 0.605 0.387\n## [3,] 0.619 0.395\n## [4,] 0.593 0.304\n## [5,] 0.697 0.389\n## [6,] 0.527 0.353\n\n# Expected values with tidybayes\ntidy_epred <- model_basic %>% \n  epred_draws(newdata = newdata)\ntidy_epred\n## # A tibble: 8,000 × 8\n## # Groups:   party_autonomy, civil_liberties, region, .row [2]\n##    party_autonomy civil_liberties region               .row .chain .iteration .draw .epred\n##    <lgl>                    <dbl> <chr>               <int>  <int>      <int> <int>  <dbl>\n##  1 TRUE                       0.5 Middle East and No…     1     NA         NA     1  0.677\n##  2 TRUE                       0.5 Middle East and No…     1     NA         NA     2  0.605\n##  3 TRUE                       0.5 Middle East and No…     1     NA         NA     3  0.619\n##  4 TRUE                       0.5 Middle East and No…     1     NA         NA     4  0.593\n##  5 TRUE                       0.5 Middle East and No…     1     NA         NA     5  0.697\n##  6 TRUE                       0.5 Middle East and No…     1     NA         NA     6  0.527\n##  7 TRUE                       0.5 Middle East and No…     1     NA         NA     7  0.756\n##  8 TRUE                       0.5 Middle East and No…     1     NA         NA     8  0.659\n##  9 TRUE                       0.5 Middle East and No…     1     NA         NA     9  0.524\n## 10 TRUE                       0.5 Middle East and No…     1     NA         NA    10  0.701\n## # ℹ 7,990 more rows\n```\n:::\n\n\nHere's what the difference in variance actually looks like:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot_preds <- bind_rows(\n  \"Predicted draws\" = tidy_pred,\n  \"Expectation of predicted draws\" = rename(tidy_epred, .prediction = .epred),\n  .id = \"draw_type\") %>% \n  mutate(draw_type = fct_inorder(draw_type))\n\nplot_preds %>% \n  group_by(draw_type, party_autonomy) %>% \n  median_hdi(.prediction)\n## # A tibble: 4 × 8\n##   draw_type               party_autonomy .prediction .lower .upper .width .point .interval\n##   <fct>                   <lgl>                <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n## 1 Predicted draws         FALSE                0.355 0.0183  0.725   0.95 median hdi      \n## 2 Predicted draws         TRUE                 0.638 0.242   0.976   0.95 median hdi      \n## 3 Expectation of predict… FALSE                0.369 0.287   0.461   0.95 median hdi      \n## 4 Expectation of predict… TRUE                 0.622 0.532   0.707   0.95 median hdi\n\nggplot(plot_preds, aes(x = .prediction, fill = party_autonomy)) +\n  stat_halfeye() +\n  labs(x = \"Predicted media index\", y = \"Density\", fill = \"Party autonomy\") +\n  facet_wrap(vars(draw_type)) +\n  scale_fill_okabe_ito() +\n  theme_clean() +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot-pred-vs-epred-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\nThe median values from both types of draws are the same. When there's no party autonomy, the median predicted media index is around 0.11; when there is party autonomy, the median predicted media index is around 0.6. But the variance is wildly different and is much narrower when looking at the expectation of predicted draws.\n\nFor all our marginal effects calculations here, we're going to use **expected values**, or `epred_draws()`.\n\n\n## Average marginal effects\n\nIn the plot above, we got predicted values of our outcome across different levels of party autonomy when holding civil liberties and region constant, and that's neat, but what we're really interested in is the *difference* between those two distributions, or the marginal effect of flipping party autonomy from false to true. How much of an increase in the predicted media index when there is party autonomy?\n\nWe already have all the information we need to calculate this with our `tidy_epred`. If we rearrange the dataset so that it's wide, with a column for party autonomy being true and a column for when it's false, we can subtract the two columns and get the difference:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntidy_epred %>% \n  ungroup() %>% \n  select(-.row) %>% \n  pivot_wider(names_from = \"party_autonomy\", values_from = \".epred\") %>% \n  mutate(autonomy_effect = `TRUE` - `FALSE`)\n## # A tibble: 4,000 × 8\n##    civil_liberties region           .chain .iteration .draw `TRUE` `FALSE` autonomy_effect\n##              <dbl> <chr>             <int>      <int> <int>  <dbl>   <dbl>           <dbl>\n##  1             0.5 Middle East and…     NA         NA     1  0.677   0.413           0.265\n##  2             0.5 Middle East and…     NA         NA     2  0.605   0.387           0.218\n##  3             0.5 Middle East and…     NA         NA     3  0.619   0.395           0.224\n##  4             0.5 Middle East and…     NA         NA     4  0.593   0.304           0.290\n##  5             0.5 Middle East and…     NA         NA     5  0.697   0.389           0.308\n##  6             0.5 Middle East and…     NA         NA     6  0.527   0.353           0.174\n##  7             0.5 Middle East and…     NA         NA     7  0.756   0.500           0.256\n##  8             0.5 Middle East and…     NA         NA     8  0.659   0.454           0.205\n##  9             0.5 Middle East and…     NA         NA     9  0.524   0.294           0.230\n## 10             0.5 Middle East and…     NA         NA    10  0.701   0.424           0.276\n## # ℹ 3,990 more rows\n```\n:::\n\n\nWe could then plot that `autonomy_effect` column and see the average marginal effect of party autonomy. But that's a lot of data wrangling and pivoting! There's an easier way! Instead of manually working with the posterior predictions like this, we can use the **emmeans** package, which was designed specifically for this kind of work.\n\nWith `emmeans()`, we don't have to create our own hypothetical `newdata` data frame—the function does that for us. We need to specify `epred = TRUE` to get the expectation of predicted draws, since it'll give us predicted draws by default.\n\nIf we run `emmeans()` by itself, it'll print a summary table of the predicted values:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel_basic %>% \n  emmeans(~ party_autonomy,\n          at = list(civil_liberties = 0.5,\n                    region = \"Middle East and North Africa\"),\n          epred = TRUE)\n##  party_autonomy emmean lower.HPD upper.HPD\n##  FALSE           0.329     0.223     0.445\n##   TRUE           0.578     0.461     0.691\n## \n## Point estimate displayed: median \n## HPD interval probability: 0.95\n```\n:::\n\n\nWe also don't need to calculate the autonomy effect by hand—the `constrast()` function will do that for us too (the `revpairwise` option here makes it so it'll calculate `TRUE - FALSE` instead of `FALSE - TRUE`):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel_basic %>% \n  emmeans(~ party_autonomy,\n          at = list(civil_liberties = 0.5,\n                    region = \"Middle East and North Africa\"),\n          epred = TRUE) %>% \n  contrast(method = \"revpairwise\")\n##  contrast     estimate lower.HPD upper.HPD\n##  TRUE - FALSE    0.246     0.171     0.327\n## \n## Point estimate displayed: median \n## HPD interval probability: 0.95\n```\n:::\n\n\nIf we store the results of `emmeans()` as an object, we actually get access to all the posterior draws that it created for the predictions, which we can then extract and rearrange with **tidybayes**'s `gather_emmeans_draws()`. (Without the `contrast()` step, we'd get predicted values for both levels of `party_autonomy`.)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautonomy_effect_draws <- model_basic %>% \n  emmeans(~ party_autonomy,\n          at = list(civil_liberties = 0.5,\n                    region = \"Middle East and North Africa\"),\n          epred = TRUE) %>% \n  contrast(method = \"revpairwise\") %>% \n  gather_emmeans_draws()\nautonomy_effect_draws\n## # A tibble: 4,000 × 5\n## # Groups:   contrast [1]\n##    contrast     .chain .iteration .draw .value\n##    <chr>         <int>      <int> <int>  <dbl>\n##  1 TRUE - FALSE     NA         NA     1  0.254\n##  2 TRUE - FALSE     NA         NA     2  0.217\n##  3 TRUE - FALSE     NA         NA     3  0.223\n##  4 TRUE - FALSE     NA         NA     4  0.292\n##  5 TRUE - FALSE     NA         NA     5  0.311\n##  6 TRUE - FALSE     NA         NA     6  0.169\n##  7 TRUE - FALSE     NA         NA     7  0.275\n##  8 TRUE - FALSE     NA         NA     8  0.205\n##  9 TRUE - FALSE     NA         NA     9  0.237\n## 10 TRUE - FALSE     NA         NA    10  0.270\n## # ℹ 3,990 more rows\n\nautonomy_effect_draws %>% median_hdi()\n## # A tibble: 1 × 7\n##   contrast     .value .lower .upper .width .point .interval\n##   <chr>         <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n## 1 TRUE - FALSE  0.246  0.171  0.327   0.95 median hdi\n\nggplot(autonomy_effect_draws, aes(x = .value)) +\n  stat_halfeye(fill = palette_okabe_ito(order = 5)) +\n  labs(x = \"Average marginal effect of party autonomy\", y = \"Density\") +\n  theme_clean() +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/autonomy-effect-emmeans-contrast-draws-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\nThat's so cool! There's our marginal effect. On average, having party autonomy is associated with a 0.247 point higher media freedom index score. Since it's measured on a 0–1 scale, that's a pretty sizable effect!\n\nWhere **emmeans** really shines is figuring out the average marginal effect for continuous predictors. Working with party autonomy was easy enough: get the predicted value when it's false, get the predicted value when it's true, and find the difference. Getting a continuous effect, though, is a lot trickier since it involves slopes and first derivatives and calculus. Plus we're working with a nonlinear model, so the slope is different across the whole range of predictions.\n\nFor instance, here's the predicted media freedom index across a range of respect for civil liberties. It's curvy! The slope is really flat down at low levels of civil liberties, and it's steep up at high levels\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npred_civlib <- model_basic %>% \n  epred_draws(newdata = expand_grid(party_autonomy = FALSE,\n                                    region = \"Middle East and North Africa\",\n                                    civil_liberties = seq(0, 1, by = 0.05)))\n\nggplot(pred_civlib, aes(x = civil_liberties, y = .epred)) +\n  stat_lineribbon() + \n  scale_fill_brewer(palette = \"Reds\") +\n  labs(x = \"Civil liberties index\", y = \"Predicted media freedom index\",\n       fill = \"Credible interval\") +\n  theme_clean() +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/civlib-effect-plot-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\nThe `emtrends()` function from **emmeans** lets us find the slope at different hypothetical values. (Technically behind the scenes, if we tell it to show us the slope when `civil_liberties` is 0.5, it'll calculate the predicted value at 0.5 and the predicted value at 0.50001, and then average those predictions, rather than try to figure out the true calculus-based derivative).\n\nIf we don't specify possible values of `civil_liberties`, it will give us the slope at the average value of `civil_liberties` (0.698):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel_basic %>% \n  emtrends(~ civil_liberties,\n           var = \"civil_liberties\",\n           at = list(party_autonomy = FALSE,\n                     region = \"Middle East and North Africa\"),\n           epred = TRUE)\n##  civil_liberties civil_liberties.trend lower.HPD upper.HPD\n##            0.696                 0.865     0.702      1.03\n## \n## Point estimate displayed: median \n## HPD interval probability: 0.95\n```\n:::\n\n\nIf we use `~ 1` in the formula instead of `~ civil_liberties`, it will give us the average overall slope:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel_basic %>% \n  emtrends(~ 1,\n           var = \"civil_liberties\",\n           at = list(party_autonomy = FALSE,\n                     region = \"Middle East and North Africa\"),\n           epred = TRUE)\n##  1       civil_liberties.trend lower.HPD upper.HPD\n##  overall                 0.865     0.702      1.03\n## \n## Point estimate displayed: median \n## HPD interval probability: 0.95\n```\n:::\n\n\nOr we can specify specific values of `civil_liberties` to get the slope at those points:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel_basic %>% \n  emtrends(~ civil_liberties,\n           var = \"civil_liberties\",\n           at = list(party_autonomy = FALSE,\n                     region = \"Middle East and North Africa\",\n                     civil_liberties = c(0.2, 0.5, 0.8)),\n           epred = TRUE)\n##  civil_liberties civil_liberties.trend lower.HPD upper.HPD\n##              0.2                 0.436     0.295     0.607\n##              0.5                 0.767     0.577     0.951\n##              0.8                 0.838     0.695     0.982\n## \n## Point estimate displayed: median \n## HPD interval probability: 0.95\n```\n:::\n\n\nThe civil liberties effect varies a lot depending on existing levels of civil liberties! Let's visualize these three effects. We'll scale the effect down, though, since civil liberties is on a 0–1 scale and a 1-unit change means going from 0 to 1, which is huge. We'll think about this as a 0.1-point increase in the civil liberties scale.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\name_civlib <- model_basic %>% \n  emtrends(~ civil_liberties,\n           var = \"civil_liberties\",\n           at = list(party_autonomy = FALSE,\n                     region = \"Middle East and North Africa\",\n                     civil_liberties = c(0.2, 0.5, 0.8)),\n           epred = TRUE) %>% \n  gather_emmeans_draws() %>% \n  # Scale this down\n  mutate(.value = .value / 10)\n\nggplot(ame_civlib, aes(x = .value, fill = factor(civil_liberties))) +\n  stat_halfeye(slab_alpha = 0.75) +\n  scale_fill_okabe_ito(order = c(3, 4, 6)) +\n  labs(x = \"Average marginal effect of a\\n0.1-point increase in the civil liberties index\",\n       y = \"Density\", fill = \"Civil liberties index\",\n       caption = \"80% and 95% credible intervals shown in black\") +\n  theme_clean() + \n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot-civlib-effect-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\nFor countries with low levels of civil liberties, a 0.1-point increase in respect for civil liberties (e.g., moving from 0.2 to 0.3) is associated with a 0.0436-point increase in the media freedom index. For a middle ground country, though, moving from 0.5 to 0.6 in civil liberties is associated with a 0.0763-point increase in the media freedom index, while countries with strong civil liberties see a strong increase in the media freedom index (0.0833 points). Cool cool cool.\n\n\n## Different kinds of average predictions with multilevel models\n\n**BUT THERE'S A HUGE CAVEAT HERE!** \n\nGuess what?! All these predicted average effects aren't quite what we think they are. (That's what TJ was referring to in the tweet at the beginning of this post!) \n\nBecause we're working with multilevel models, we actually have other moving parts to think about: the regional effects. When we talk about average marginal effects with multilevel models, we have to be explicit about what kinds of averages we're working with. There are a few different kinds of averages we can calculate:\n\n- Global grand mean\n- Conditional effects for existing groups\n- Conditional effects for a single hypothetical group, either typical or brand new\n\nWe can specify all these different kinds of calculations with certain combinations of a few arguments to `posterior_epred()` / `epred_draws()` / `emmeans()` / `emmtrends()`:\n\n- `newdata`: Specify which regions to include in the predictions\n- `re_formula`: Specify how (and whether) to handle the model's random effects in the predictions\n- `sample_new_levels`: Specify how to handle the uncertainty in new random effects in the predictions\n\n(These are all documented in the help pages for `?brms::prepare_predictions()`)\n\n\n### Global grand mean\n\nWith a global grand mean, we calculate the expected value of the media freedom index **while ignoring any region-specific deviations of the intercept or slope.** We do not incorporate any of the region-specific information from the model into the predictions. This provides us with a global grand mean—an average that transcends regional differences.\n\nTo calculate this, we need to feed **brms** a new dataset that doesn't include any region, and we need to tell it to not use any random effects by including `re_formula = NA`. \n\n#### Binary effect\n\nLet's look at the global average marginal effect for party autonomy, which is binary:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Posterior predictions across autonomy\ngrand_mean_autonomy_dist <- model_basic %>% \n  epred_draws(newdata = expand_grid(party_autonomy = c(TRUE, FALSE),\n                                    civil_liberties = c(0.5)), \n              re_formula = NA)\n\nplot_grand_mean_autonomy <- ggplot(grand_mean_autonomy_dist, \n                                   aes(x = .epred, y = \"Grand mean\", \n                                       fill = party_autonomy)) +\n  stat_halfeye() +\n  scale_fill_okabe_ito() +\n  labs(x = \"Predicted media index\", y = NULL,\n       fill = \"Opposition parties allowed\",\n       subtitle = \"Posterior predictions\") +\n  theme_clean() +\n  theme(legend.position = \"bottom\")\n\n# emmeans()-based difference across autonomy\ngrand_mean_autonomy_ame <- model_basic %>% \n  emmeans(~ party_autonomy,\n          at = list(civil_liberties = 0.5),\n          epred = TRUE, re_formula = NA) %>% \n  contrast(method = \"revpairwise\") %>% \n  gather_emmeans_draws()\n\nplot_grand_mean_autonomy_ame <- ggplot(grand_mean_autonomy_ame, \n                                   aes(x = .value, y = \"Grand AME\")) +\n  stat_halfeye(fill = palette_okabe_ito(order = 7)) +\n  labs(x = \"Average marginal effect of party autonomy\", y = NULL,\n       subtitle = \"Marginal effect (TRUE − FALSE)\") +\n  theme_clean() +\n  theme(legend.position = \"bottom\")\n\n# Combined plot\n(plot_grand_mean_autonomy | plot_grand_mean_autonomy_ame) +\n  plot_annotation(title = \"Global grand mean\",\n                  subtitle = \"re_formula = NA; no region in newdata\",\n                  theme = theme_clean())\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot-grand-mean-binary-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\nAnd here are the actual medians and credible intervals:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngrand_mean_autonomy_ame %>% median_hdi()\n## # A tibble: 1 × 7\n##   contrast     .value .lower .upper .width .point .interval\n##   <chr>         <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n## 1 TRUE - FALSE  0.246  0.171  0.327   0.95 median hdi\n```\n:::\n\n\nThe region-free grand average marginal effect for party autonomy is thus 0.247.\n\n#### Continuous effect\n\nNext we can look at the average marginal effect for civil liberties, which is continuous:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Posterior predictions across civil_liberties\ngrand_mean_civlib_dist <- model_basic %>% \n  epred_draws(newdata = expand_grid(party_autonomy = FALSE,\n                                    civil_liberties = seq(0, 1, by = 0.05)), \n              re_formula = NA)\n\nplot_grand_mean_civlib <- ggplot(grand_mean_civlib_dist, \n                                 aes(x = civil_liberties, y = .epred)) +\n  stat_lineribbon() +\n  scale_fill_brewer(palette = \"Reds\") +\n  labs(x = \"Civil liberties index\", y = \"Predicted media freedom index\",\n       fill = \"Credible interval\") +\n  theme_clean() +\n  theme(legend.position = \"bottom\")\n\n# emtrends()-based AMEs\ngrand_mean_civlib_ame <- model_basic %>% \n  emtrends(~ civil_liberties,\n           var = \"civil_liberties\",\n           at = list(party_autonomy = FALSE,\n                     civil_liberties = c(0.2, 0.8)),\n           epred = TRUE, re_formula = NA) %>% \n  gather_emmeans_draws()\n\nplot_grand_mean_civlib_ame <- ggplot(grand_mean_civlib_ame,\n                                     aes(x = .value / 10, fill = factor(civil_liberties))) +\n  stat_halfeye(slab_alpha = 0.75) +\n  scale_fill_okabe_ito(order = c(3, 4)) +\n  labs(x = \"Average marginal effect of a\\n0.1-point increase in the civil liberties index\",\n       y = \"Density\", fill = \"Civil liberties index\") +\n  theme_clean() + \n  theme(legend.position = \"bottom\")\n\n# Combined plot\n(plot_grand_mean_civlib | plot_grand_mean_civlib_ame) +\n  plot_annotation(title = \"Grand mean\",\n                  subtitle = \"re_formula = NA; no region in newdata\",\n                  theme = theme_clean())\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot-grand-mean-continuous-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\nAnd here are the actual medians for these effects:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngrand_mean_civlib_ame %>% median_hdi()\n## # A tibble: 2 × 7\n##   civil_liberties .value .lower .upper .width .point .interval\n##             <dbl>  <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n## 1             0.2  0.436  0.295  0.607   0.95 median hdi      \n## 2             0.8  0.838  0.695  0.982   0.95 median hdi\n```\n:::\n\n\nThe region-free grand average marginal effect for civil liberties is 0.436 for low values of civil liberties (0.2), and 0.833 for high values (0.8).\n\n### Conditional effects for existing groups\n\nInstead of calculating a grand mean without any group information, we can incorporate regional effects into our predictions. We can create **conditional effects for specific regions that already exist in the data, incorporating their region-specific deviations in slope and intercept.**\n\nTo calculate this, we need to feed **brms** a new dataset that *does* include one or more regions that are already in the data, and we need to tell it to incorporate the random effects into its predictions by including `re_formula = NULL`. That feels weird, since `re_formula = NA` made it so there were no group effects, but that's the syntax. \n\nWe can also be more explicit about which group effects to include. When using `re_formula = NULL`, *all* group effects are included. If we made a model with both region and year effects, for instance, and only wanted to predict using the region effects, we could use `re_formula = ~ (1 | region)`. Or if we don't want to remember that `NULL` means \"everything\", we could also just use `re_formula = ~ (1 | region)` on our basic model with just regional effects. It's all the same.\n\n#### Binary effect\n\nLet's look at the binary region-specific average marginal effect for party autonomy across all six regions:\n\n\n::: {.cell layout-align=\"center\" fig.asp='0.7'}\n\n```{.r .cell-code}\n# Posterior predictions across autonomy and region\nall_regions_autonomy_dist <- model_basic %>% \n  epred_draws(newdata = expand_grid(party_autonomy = c(TRUE, FALSE),\n                                    region = levels(vdem_2015$region),\n                                    civil_liberties = c(0.5)), \n              re_formula = NULL)  # or re_formula = ~ (1 | region)\n\nplot_all_regions_autonomy <- ggplot(all_regions_autonomy_dist, \n                                    aes(x = .epred, y = region, \n                                        fill = party_autonomy)) +\n  stat_halfeye() +\n  scale_fill_okabe_ito() +\n  labs(x = \"Predicted media index\", y = NULL,\n       fill = \"Opposition parties allowed\",\n       subtitle = \"Posterior predictions\") +\n  theme_clean() +\n  theme(legend.position = \"bottom\")\n\n# emmeans()-based difference across autonomy, by region\nall_regions_autonomy_ame <- model_basic %>% \n  emmeans(~ party_autonomy + region,\n          at = list(civil_liberties = 0.5,\n                    region = levels(vdem_2015$region)),\n          epred = TRUE, re_formula = NULL) %>% \n  contrast(method = \"revpairwise\", by = \"region\") %>% \n  gather_emmeans_draws()\n\nplot_all_regions_autonomy_ame <- ggplot(all_regions_autonomy_ame, \n                                        aes(x = .value, y = region)) +\n  stat_halfeye(fill = palette_okabe_ito(order = 7)) +\n  labs(x = \"Average marginal effect of party autonomy\", y = NULL,\n       subtitle = \"Marginal effect (TRUE − FALSE)\") +\n  theme_clean() +\n  theme(legend.position = \"bottom\")\n\n# Combined plot\n(plot_all_regions_autonomy | plot_all_regions_autonomy_ame + theme(axis.text.y = element_blank())) +\n  plot_annotation(title = \"Region-specific means\",\n                  subtitle = \"re_formula = NULL; existing region(s) included in newdata\",\n                  theme = theme_clean())\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot-all-regions-binary-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\nAnd here are the actual medians and credible intervals:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nall_regions_autonomy_ame %>% median_hdi()\n## # A tibble: 6 × 8\n##   contrast     region                         .value .lower .upper .width .point .interval\n##   <fct>        <fct>                           <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n## 1 TRUE - FALSE Eastern Europe and Central As…  0.231  0.155  0.303   0.95 median hdi      \n## 2 TRUE - FALSE Latin America and the Caribbe…  0.241  0.161  0.314   0.95 median hdi      \n## 3 TRUE - FALSE Middle East and North Africa    0.250  0.172  0.330   0.95 median hdi      \n## 4 TRUE - FALSE Sub-Saharan Africa              0.250  0.173  0.330   0.95 median hdi      \n## 5 TRUE - FALSE Western Europe and North Amer…  0.243  0.162  0.320   0.95 median hdi      \n## 6 TRUE - FALSE Asia and Pacific                0.239  0.166  0.314   0.95 median hdi\n```\n:::\n\n\nThe average marginal effect changes depending on region, but not by much. Across all regions, having party autonomy is associated with a 0.24 to 0.25-point increase in the media freedom index, on average. Importantly, these average effects incorporate the uncertainty that comes from the regional multilevel structure that we built in the model.\n\n#### Continuous effect\n\nNext we'll look at the continuous region-specific average marginal effect for civil liberties across all six regions:\n\n\n::: {.cell layout-align=\"center\" fig.asp='1.3'}\n\n```{.r .cell-code}\n# Posterior predictions across civil_liberties and regions\nall_regions_civlib_dist <- model_basic %>% \n  epred_draws(newdata = expand_grid(party_autonomy = FALSE,\n                                    civil_liberties = seq(0, 1, by = 0.05),\n                                    region = levels(vdem_2015$region)), \n              re_formula = NULL)\n\nplot_all_regions_civlib <- ggplot(all_regions_civlib_dist, \n                                  aes(x = civil_liberties, y = .epred)) +\n  stat_lineribbon() +\n  scale_fill_brewer(palette = \"Reds\") +\n  labs(x = \"Civil liberties index\", y = \"Predicted media freedom index\",\n       fill = \"Credible interval\") +\n  facet_wrap(vars(region)) +\n  theme_clean() +\n  theme(legend.position = \"bottom\")\n\n# emtrends()-based AMEs across region\nall_regions_civlib_ame <- model_basic %>% \n  emtrends(~ civil_liberties + region,\n           var = \"civil_liberties\",\n           at = list(party_autonomy = FALSE,\n                     civil_liberties = c(0.2, 0.8),\n                     region = levels(vdem_2015$region)),\n           epred = TRUE, re_formula = NULL) %>% \n  gather_emmeans_draws()\n\nplot_all_regions_civlib_ame <- ggplot(all_regions_civlib_ame,\n                                     aes(x = .value / 10, fill = factor(civil_liberties))) +\n  stat_halfeye(slab_alpha = 0.75) +\n  scale_fill_okabe_ito(order = c(3, 4)) +\n  labs(x = \"Average marginal effect of a\\n0.1-point increase in the civil liberties index\",\n       y = \"Density\", fill = \"Civil liberties index\") +\n  facet_wrap(vars(region)) +\n  theme_clean() + \n  theme(legend.position = \"bottom\")\n\n(plot_all_regions_civlib / plot_all_regions_civlib_ame) +\n  plot_annotation(title = \"Region-specific means\",\n                  subtitle = \"re_formula = NULL; existing region(s) included in newdata\",\n                  theme = theme_clean())\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot-all-regions-continuous-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\nAnd here are the actual medians for these effects:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nall_regions_civlib_ame %>% median_hdi()\n## # A tibble: 12 × 8\n##    civil_liberties region                     .value .lower .upper .width .point .interval\n##              <dbl> <fct>                       <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n##  1             0.2 Eastern Europe and Centra…  0.327  0.246  0.418   0.95 median hdi      \n##  2             0.2 Latin America and the Car…  0.380  0.290  0.475   0.95 median hdi      \n##  3             0.2 Middle East and North Afr…  0.492  0.377  0.638   0.95 median hdi      \n##  4             0.2 Sub-Saharan Africa          0.479  0.373  0.590   0.95 median hdi      \n##  5             0.2 Western Europe and North …  0.609  0.469  0.729   0.95 median hdi      \n##  6             0.2 Asia and Pacific            0.366  0.267  0.479   0.95 median hdi      \n##  7             0.8 Eastern Europe and Centra…  0.871  0.709  1.02    0.95 median hdi      \n##  8             0.8 Latin America and the Car…  0.865  0.725  1.01    0.95 median hdi      \n##  9             0.8 Middle East and North Afr…  0.808  0.687  0.924   0.95 median hdi      \n## 10             0.8 Sub-Saharan Africa          0.819  0.708  0.926   0.95 median hdi      \n## 11             0.8 Western Europe and North …  0.724  0.585  0.885   0.95 median hdi      \n## 12             0.8 Asia and Pacific            0.865  0.712  1.00    0.95 median hdi\n```\n:::\n\n\nAs expected, the average marginal effect for civil liberties varies across regions. For the Middle East and North Africa, for instance, it is 0.49 for low values of civil liberties (0.2), and 0.8 for high values (0.8), while in Eastern Europe and Central Asia, it is 0.328 for low values and 0.865 for high values.\n\nNeat!\n\n### Conditional effects for a single new hypothetical group, either typical or brand new\n\nSo far we've calculated a grand mean with no regional effects and a bunch of conditional means for specific regions. But what if we want a single mean that also includes regional effects?\n\nWe have a few really nuanced options for doing this. In general, we'll create a brand new hypothetical region and make predictions based on it. Where the nuance comes into play is how we construct this region and think about its variation. We can build its variance based on an average of the existing regions' variances, or we can simulate a brand new kind of variance all together.\n\nTo do this, we need to include region in the new data we feed **brms**, but we need to include a name of a region that doesn't exist (or alternatively, you can feed it `region = NA`). It will yell at you initially because that group doesn't exist, but you can allow it to make these extrapolated predictions by including `allow_new_levels = TRUE`. We can include the random effects for region by setting `re_formula = NULL` (or `re_formula = ~ (1 | region)` if we want to be super explicit).\n\nFinally, we have to specify how to handle the regional variation for this imaginary new group. We can either draw from the variation in all the other groups by setting `sample_new_levels = \"uncertainty\"` (this is the default), or we can randomly simulate a whole new kind of regional uncertainty based on the model's existing parameters using `sample_new_levels = \"gaussian\"`. The documentation for all this is included in `?brms::prepare_predictions`.\n\nIn summary, we have these two general approaches:\n\n1. Create a hypothetical region that is based on the observed variation in the existing regions with `region = \"Something new\"` in the new data and `re_formula = NULL, allow_new_levels = TRUE, sample_new_levels = \"uncertainty\"` in the prediction function\n2. Create a hypothetical region that is completely brand new with `region = \"Something new\"` in the new data and `re_formula = NULL, allow_new_levels = TRUE, sample_new_levels = \"gaussian\"` in the prediction function\n\nFor the sake of space I'll only show marginal effects for the binary `party_autonomy` variable here. Follow the same process as all the examples above, but set `re_formula = NULL`, `allow_new_levels = TRUE`, and either `sample_new_levels = \"uncertainty\"` or `sample_new_levels = \"gaussian\"` when making the predictions.\n\nTechnically there are other ways to create simulated groups or regions, like `sample_new_levels = \"old_levels\"`. Isabella Ghement has a [great comprehensive table summarizing them all here](https://twitter.com/isabellaghement/status/1458539033131302913). But we're not going to worry about that here.\n\n#### Binary effect for amalgamated hypothetical region\n\nFirst we'll create predictions for a hypothetical region that draws its group characteristics and variance from all the other regions in the data. To do this, we include `region = \"Something new\"` in the new data and `re_formula = NULL, allow_new_levels = TRUE, sample_new_levels = \"uncertainty\"` in the prediction function.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\name_hypothetical_amalgamated <- model_basic %>% \n  emmeans(~ party_autonomy + region,\n          at = list(civil_liberties = 0.5, \n                    region = \"Generic world region\"),\n          epred = TRUE, re_formula = NULL, \n          allow_new_levels = TRUE, sample_new_levels = \"uncertainty\") %>% \n  contrast(method = \"revpairwise\") %>% \n  gather_emmeans_draws()\n\name_hypothetical_amalgamated %>% median_hdi()\n## # A tibble: 1 × 7\n##   contrast                                    .value .lower .upper .width .point .interval\n##   <chr>                                        <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n## 1 TRUE Generic world region - FALSE Generic …  0.243  0.164  0.320   0.95 median hdi\n\nplot_ame_hypothetical_amalgamated <- ggplot(ame_hypothetical_amalgamated, \n                                            aes(x = .value, y = \"Generic world region\")) +\n  stat_halfeye(fill = palette_okabe_ito(order = 7)) +\n  labs(x = \"Average marginal effect of party autonomy\", y = NULL,\n       title = \"Marginal effect in a generic world region\") +\n  theme_clean() +\n  theme(legend.position = \"bottom\")\nplot_ame_hypothetical_amalgamated\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot-ame-generic-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\nIn this case, the distribution is pretty smooth and normal looking, but if there's a lot of variation in regional distributions, that variation will transfer to these predictions too.\n\nFor instance, in an earlier working version of this post, I had region-specific average predictions that varied substantially across regions. The resulting new hypothetical region reflected those different components—because the new generic world region is an amalgamation of uncertainty of all the existing regions, it includes both high values and low values ([thanks to TJ Mahr for this insight!](https://twitter.com/tjmahr/status/1458443667748818955)):\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](tj-annotation.jpg){fig-align='center' width=100%}\n:::\n:::\n\n\n#### Binary effect for completely new hypothetical region\n\nAlternatively, we can make it so that the new fake region uses a multivariate normal distribution implied by the model's group-level standard deviations and correlations. This creates a brand new region that would be plausible in the universe, but that is not sampled directly from the existing regions. As a result, there's no possibility of a weird bimodal blip—the overall shape of the distribution will be much smoother and consistent.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\name_hypothetical_new <- model_basic %>% \n  emmeans(~ party_autonomy + region,\n          at = list(civil_liberties = 0.5, \n                    region = \"Atlantis\"),\n          epred = TRUE, re_formula = NULL, \n          allow_new_levels = TRUE, sample_new_levels = \"gaussian\") %>% \n  contrast(method = \"revpairwise\") %>% \n  gather_emmeans_draws()\n\name_hypothetical_new %>% median_hdi()\n## # A tibble: 1 × 7\n##   contrast                       .value .lower .upper .width .point .interval\n##   <chr>                           <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n## 1 TRUE Atlantis - FALSE Atlantis  0.235  0.141  0.325   0.95 median hdi\n\nplot_ame_hypothetical_new <- ggplot(ame_hypothetical_new, \n                                            aes(x = .value, y = \"Atlantis\")) +\n  stat_halfeye(fill = palette_okabe_ito(order = 7)) +\n  labs(x = \"Average marginal effect of party autonomy\", y = NULL,\n       title = \"Marginal effect in the Atlantis region\") +\n  theme_clean() +\n  theme(legend.position = \"bottom\")\nplot_ame_hypothetical_new\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot-ame-atlantis-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n## Which average is best?\n\nYou've run a great multilevel model and want to report the average marginal effects for your coefficients of interest. Which average do you report? The global grand mean? Means conditional on existing groups? The mean of a new typical-ish looking region? The mean of a completely brand new region?\n\nWho knows!\n\nIt all depends on the story you're trying to tell about your data, theory, and results.\n\n\n## Overall summary of different approaches\n\nPhew. We did a lot here with a ton of really neat moving parts. Here's a summary of all the different average effects you can calculate with multilevel models and how to do them:\n\n\n::: {.cell .column-page-inset-right layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Type of average </th>\n   <th style=\"text-align:left;\"> Description </th>\n   <th style=\"text-align:left;\"> <code>newdata</code> </th>\n   <th style=\"text-align:left;\"> <code>re_formula</code> </th>\n   <th style=\"text-align:left;\"> Other options </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Global grand mean </td>\n   <td style=\"text-align:left;\"> Average predicted outcome ignoring group-specific deviations in intercept or slope </td>\n   <td style=\"text-align:left;\"> Omit group from <code>newdata</code> </td>\n   <td style=\"text-align:left;\"> <code>re_formula = NA</code> </td>\n   <td style=\"text-align:left;\"> — </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Conditional effects for existing groups </td>\n   <td style=\"text-align:left;\"> Average predicted outcomes for existing groups, incorporating group-specific deviations in intercept or slope </td>\n   <td style=\"text-align:left;\"> Include existing group(s) in <code>newdata</code> </td>\n   <td style=\"text-align:left;\"> <code>re_formula = NULL</code> or actual group term, like <code>re_formula = ~ (1 | group)</code> </td>\n   <td style=\"text-align:left;\"> — </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Conditional effects for a single typical hypothetical group </td>\n   <td style=\"text-align:left;\"> Average predicted outcome for a new group that is based on variation of existing groups </td>\n   <td style=\"text-align:left;\"> Include new group in <code>newdata</code> </td>\n   <td style=\"text-align:left;\"> <code>re_formula = NULL</code> or actual group term, like <code>re_formula = ~ (1 | group)</code> </td>\n   <td style=\"text-align:left;\"> <code>allow_new_levels = TRUE,</code><br><code>sample_new_levels = \"uncertainty\"</code> </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Conditional effects for a single brand new hypothetical group </td>\n   <td style=\"text-align:left;\"> Average predicted outcome for a new group that is based on random draws from model </td>\n   <td style=\"text-align:left;\"> Include new group in <code>newdata</code> </td>\n   <td style=\"text-align:left;\"> <code>re_formula = NULL</code> or actual group term, like <code>re_formula = ~ (1 | group)</code> </td>\n   <td style=\"text-align:left;\"> <code>allow_new_levels = TRUE,</code><br><code>sample_new_levels = \"gaussian\"</code> </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\\ \n\n\n::: {.cell .column-page-inset-right layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Type of average </th>\n   <th style=\"text-align:left;\"> Generic code </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Global grand mean </td>\n   <td style=\"text-align:left;\"> <pre><code>posterior_epred(model,<br>                newdata = __OMIT GROUP__,<br>                re_formula = NA)<code></code></code></pre> </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Conditional effects for existing groups </td>\n   <td style=\"text-align:left;\"> <pre><code>posterior_epred(model,<br>                newdata = __INCLUDE EXISTING GROUP(S)__,<br>                re_formula = NULL)<code></code></code></pre> </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Conditional effects for a single typical hypothetical group </td>\n   <td style=\"text-align:left;\"> <pre><code>posterior_epred(model,<br>                newdata = __INCLUDE NEW GROUP__,<br>                re_formula = NULL, allow_new_levels = TRUE,<br>                sample_new_levels = \"uncertainty\")<code></code></code></pre> </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Conditional effects for a single brand new hypothetical group </td>\n   <td style=\"text-align:left;\"> <pre><code>posterior_epred(model,<br>                newdata = __INCLUDE NEW GROUP__,<br>                re_formula = NULL, allow_new_levels = TRUE,<br>                sample_new_levels = \"gaussian\")<code></code></code></pre> </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nAnd here's what they all look like!\n\n\n::: {.cell .column-page-inset-right layout-align=\"center\" fig.asp='{}'}\n::: {.cell-output-display}\n![](index_files/figure-html/all-effects-combined-1.png){fig-align='center' width=100%}\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../../../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../../../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}