{
  "hash": "75ad395fbd19123c103c78a34a8e973c",
  "result": {
    "markdown": "---\ntitle: \"Marginal structural models for panel data with GEE and multilevel models\"\ndate: 2021-01-15\ndescription: \"Use R to correctly close backdoor confounding in panel data with marginal structural models and inverse probability weights with both GEE and multilevel models\"\nimage: index_files/figure-html/depression-dag-1.png\ncategories: \n  - r\n  - tidyverse\n  - causal inference\n  - DAGs\n  - do calculus\n  - inverse probability weighting\ndoi: 10.59350/yqs5b-36r77\ncitation: true\n---\n\n\n\n\nSince my last two blog posts on [binary and continuous inverse probability weights (IPWs)](https://www.andrewheiss.com/blog/2020/12/01/ipw-binary-continuous/) and [marginal structural models (MSMs) for time-series cross-sectional (TSCS) panel data](https://www.andrewheiss.com/blog/2020/12/03/ipw-tscs-msm/), I've spent a ton of time trying to figure out why I couldn't recover the exact causal effect I had built in to those examples when using panel data. It was a mystery, and it took weeks to figure out what was happening. \n\nAfter poring through all sorts of articles on MSMs and TSCS data like @ThoemmesOng:2016 and @BlackwellGlynn:2018, along with all sorts of articles on the differences between [generalized estimating equations (GEEs)](https://en.wikipedia.org/wiki/Generalized_estimating_equation), which the epidemiology world (and everyone who does MSMs) seems to love, and multilevel models (which I find a lot more intuitive, and which can be done Bayesianly with **brms**), I *finally* figured out what was wrong and how to calculate correct IPWs for panel data.\n\nThe main issue lies in the synthetic data I had created for those earlier blog posts. [There, I used the **fabricatr** package to create a country-year panel](https://www.andrewheiss.com/blog/2020/12/03/ipw-tscs-msm/#simulated-time-series-cross-sectional-data), which seemed correct and great. However, it didn't exactly match the data-generating process in situations where the value in one time period (like $X_t$) depends on the value from the previous time period (or $X_{t-1}$), or autocorrelation. As such, I couldn't quite get the correct causal effects out (since the data didn't show interdepdency across time). \n\nAfter lots of struggle, though, I finally figured out a way to explicitly build this autocorrelation in. And thanks to this delightfully accessible article by @ThoemmesOng:2016 ([ungated free version here](https://anthonyongphd.files.wordpress.com/2016/02/emerging-adulthood-2016-thoemmes-40-59.pdf)), I found clear code for MSMs that I could expand to test on more complex panel data. \n\nIn this post, I'll do a few things: (1) recreate the two-time-period example from Thoemmes and Ong's appendix (which is stuck in a PDF and really hard to copy/paste out), (2) redo their two-period example with a tidier approach, and (3) expand their two-period approach to multiple years and replace GEEs with multilevel models.\n\nHere we go!\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(ggdag)\nlibrary(dagitty)\nlibrary(ipw)  # For automatically calculating IPWs\nlibrary(geepack)  # For GEE models\nlibrary(lme4)  # For mixed/multilevel models\nlibrary(broom.mixed)\nlibrary(kableExtra)\n```\n:::\n\n\n\n## Synthetic data overview\n\nIn their paper, Thoemmes and Ong create simulated data based on this DAG, with a time-varying treatment, a non-time-varying confounder, and a time-varying outcome (depression):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\n# I generally prefer the easier-to-read formula syntax in dagify() (i.e. D1 ~ T1\n# + C, etc.), but it doesn't work with subscripted numbers like T[1], so we have\n# to use this dagitty syntax instead\ndepression_dag <- dagitty('dag {\n\"C\" [pos=\"2.5,2\"]\n\"T[1]\" [pos=\"1,1\"]\n\"D[1]\" [pos=\"2,1\"]\n\"T[2]\" [pos=\"3,1\"]\n\"D[2]\" [pos=\"4,1\"]\n\"C\" -> \"D[1]\"\n\"C\" -> \"D[2]\"\n\"C\" -> \"T[1]\"\n\"C\" -> \"T[2]\"\n\"D[1]\" -> \"T[2]\"\n\"T[1]\" -> \"D[1]\"\n\"T[2]\" -> \"D[2]\"\n}') %>% \n  tidy_dagitty()\n\nggplot(depression_dag, aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_edges() +\n  geom_dag_point(color = \"grey80\", size = 12) +\n  geom_dag_text(color = \"black\", size = 5, parse = TRUE) +\n  theme_dag()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/depression-dag-1.png){fig-align='center' width=75%}\n:::\n:::\n\n\nEssentially earlier treatment ($T_1$) causes some level of depression ($D_1$), which causes later treatment ($T_2$), which causes later depression ($D_2$). This whole chain is influenced by some non-varying confounder ($C$).\n\n## Original two-period Thoemmes and Ong results\n\nHere's the original code from the appendix of @ThoemmesOng:2016 for data with a time-varying continuous treatment and a confounder. It explicitly creates columns for `t1`, `d1`, `t2`, and `d2`, so it is easy to mathematically make it so that `t2` is caused by `d1`.\n\nBecause it's only two time periods, they calculate the inverse probability weights in two formulas and then multiply them together:\n\n- Weights for the first time period:\n\n    $$\n    w_1 = \\frac{\\phi(T_{i1})}{\\phi(T_{i1}\\ |\\ C)}\n    $$\n\n- Weights for the second time period:\n\n    $$\n    w_2 = \\frac{\\phi(T_{i2}\\ |\\ T_{i1})}{\\phi(T_{i2}\\ |\\ C, T_{i1}, D_{i1})}\n    $$\n\n- Final weights:\n\n    $$\n    w = w_1 \\cdot w_2\n    $$\n\nHere's their code:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\n##################################################################### \n# iptw demo with time-varying continuous treatment and confounder\n#####################################################################\n# Felix Thoemmes, October, 2015 \n#####################################################################\n\n#set seed to replicate results\nset.seed(12345)\n#define sample size\nn <- 2000\n#define confounder c\nc <- rnorm(n,0,1)\n#define treatment at time 1 as function of confounder\nt1 <- .1*c + rnorm(n,0, sqrt(.99))\n#define depression at time 1 as function of confounder and treat1\nd1 <- .1*c + .4*t1 + rnorm(n,0, sqrt(.822))\n#define treatment at time 2 as function of confounder and dep1\nt2 <- .1*c + .4*d1 + .4*t1 + rnorm(n,0, sqrt(.5196))\n#define outcome depression at time 2 as function of confounder, treat1, and dep1 \nd2 <- .1*c + .4*t2 + .4*d1 + rnorm(n,0, sqrt(.4582))\n#add ID variable to do mixed effects models later\nid <- rep(1:length(c))\n\ndf1 <- data.frame(id, c, t1, d1, t2, d2)\n\n#compute the weights for timepoint 1\n#this is a continuous treatment\n#therefore we use densities of normal distributions\n#weights at time 1\nw1 <- dnorm(df1$t1, predict(lm(t1 ~ 1)), sd(lm(t1 ~ 1)$residuals)) / \n  dnorm(df1$t1, predict(lm(t1 ~ c)), sd(lm(t1 ~ c)$residuals))\n\n#weights at time 2\nw2 <- dnorm(df1$t2, predict(lm(t2 ~ t1)), sd(lm(t2 ~ t1)$residuals)) / \n  dnorm(df1$t2, predict(lm(t2 ~ c + d1 + t1)), sd(lm(t2 ~ c + d1 + t1)$residuals)) \n\n#total weights are a product of all time-varying weights\nw <- w1*w2\n\n#truncate weights at 5%\ntw1 <- ifelse(w < quantile(w, probs = .05), quantile(w, probs = 0.05), w)\ntw1 <- ifelse(w > quantile(w, probs = .95), quantile(w, probs = 0.95), tw1)\n\n#truncate weights at 1%\ntw2 <- ifelse(w < quantile(w, probs = .01), quantile(w, probs = 0.01), w)\ntw2 <- ifelse(w > quantile(w, probs = .99), quantile(w, probs = 0.99), tw2)\n```\n:::\n\n\nThey they run a bunch of different outcome models with `geeglm()`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nonly_t1 <- geeglm(d2 ~ t1, data = df1, id = rownames(df1))\nonly_t2 <- geeglm(d2 ~ t2, data = df1, id = rownames(df1))\nboth_t <- geeglm(d2 ~ t1 + t2, data = df1, id = rownames(df1))\nboth_t_c <- geeglm(d2 ~ t1 + t2 + c + d1, data = df1, id = rownames(df1))\n\nstab_ipw <- geeglm(d2 ~ t1 + t2, data = df1, id = rownames(df1), weights = w)\nstab_ipw_1p <- geeglm(d2 ~ t1 + t2, data = df1, id = rownames(df1), weights = tw2)\nstab_ipw_5p <- geeglm(d2 ~ t1 + t2, data = df1, id = rownames(df1), weights = tw1)\n\nresults <- tribble(\n  ~`Method`, ~`T<sub>1</sub> effect`, ~`T<sub>2</sub> effect`,\n  \"True effect\", 0.160, 0.400,\n  \"Naive, only T1\", filter(tidy(only_t1), term == \"t1\")$estimate, NA,\n  \"Naive, only T2\", NA, filter(tidy(only_t2), term == \"t2\")$estimate,\n  \"Naive, both\", filter(tidy(both_t), term == \"t1\")$estimate, filter(tidy(both_t), term == \"t2\")$estimate,\n  \"Naive, both + controls\", filter(tidy(both_t_c), term == \"t1\")$estimate, filter(tidy(both_t_c), term == \"t2\")$estimate,\n  \"IPW\", filter(tidy(stab_ipw), term == \"t1\")$estimate, filter(tidy(stab_ipw), term == \"t2\")$estimate,\n  \"IPW, 1% truncated\", filter(tidy(stab_ipw_1p), term == \"t1\")$estimate, filter(tidy(stab_ipw_1p), term == \"t2\")$estimate,\n  \"IPW, 5% truncated\", filter(tidy(stab_ipw_5p), term == \"t1\")$estimate, filter(tidy(stab_ipw_5p), term == \"t2\")$estimate\n)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table style=\"width:70%; margin-left: auto; margin-right: auto;\" class=\" table table-sm\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Method </th>\n   <th style=\"text-align:right;\"> T<sub>1</sub> effect </th>\n   <th style=\"text-align:right;\"> T<sub>2</sub> effect </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> True effect </td>\n   <td style=\"text-align:right;\"> 0.160 </td>\n   <td style=\"text-align:right;\"> 0.400 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Naive, only T1 </td>\n   <td style=\"text-align:right;\"> 0.423 </td>\n   <td style=\"text-align:right;\"> — </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Naive, only T2 </td>\n   <td style=\"text-align:right;\"> — </td>\n   <td style=\"text-align:right;\"> 0.649 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Naive, both </td>\n   <td style=\"text-align:right;\"> 0.048 </td>\n   <td style=\"text-align:right;\"> 0.623 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Naive, both + controls </td>\n   <td style=\"text-align:right;\"> 0.011 </td>\n   <td style=\"text-align:right;\"> 0.399 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> IPW </td>\n   <td style=\"text-align:right;\"> 0.157 </td>\n   <td style=\"text-align:right;\"> 0.421 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> IPW, 1% truncated </td>\n   <td style=\"text-align:right;\"> 0.154 </td>\n   <td style=\"text-align:right;\"> 0.434 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> IPW, 5% truncated </td>\n   <td style=\"text-align:right;\"> 0.131 </td>\n   <td style=\"text-align:right;\"> 0.480 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nAnd here's all that compared to what they have in the paper:\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](ThoemmesOng-Table2.png){fig-align='center' width=70%}\n:::\n:::\n\n\nIt's identical! I'm chalking any tiny differences up to the fact that `set.seed()` changed with R 4.0 and they used R 3.x in their paper. (Also the T2-only model is wrong, but that's probably a typo—the \"estimated scale parameter\" from that model is 0.574 with an sd of 0.018, which lines up perfectly with the coefficient in the published table, so I think maybe the published paper has the wrong number in the table.)\n\nAlso, there seems to be another typo in that table. The true effect of T1 in the table is 0.140, but in the text of the paper, it says the effect should be 0.160, which makes sense—that's the product of 0.4 × 0.4, or each of the treatment coefficients ($0.4 \\times 0.4 = 0.16$).\n\nRegardless of those super tiny insignificant typos, we did it! We have their exact results using marginal structural models and inverse probability weights.\n\n\n## Tidier two-period results\n\nThe code to generate that data isn't very tidyverse-friendly and it creates a ton of intermediate vectors. Here's a cleaner version with **dplyr**:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(12345)\nn <- 2000\n\ndf_nice <- tibble(id = 1:n,\n                  c = rnorm(n, 0, 1)) %>% \n  mutate(t1 = (0.1 * c) + rnorm(n, 0, sqrt(0.99)),\n         d1 = (0.1 * c) + (0.4 * t1) + rnorm(n, 0, sqrt(0.822)),\n         t2 = (0.1 * c) + (0.4 * d1) + (0.4 * t1) + rnorm(n, 0, sqrt(0.5196)),\n         d2 = (0.1 * c) + (0.4 * t2) + (0.4 * d1) + rnorm(n, 0, sqrt(0.4582)))\n```\n:::\n\n\nAlso, this original data is wide, with explicit columns for each time period. Let's make it tidy and pretend the time periods are years (`y`) and add some lagged columns:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf_tidy <- df_nice %>% \n  pivot_longer(cols = c(t1, d1, t2, d2)) %>% \n  separate(name, into = c(\"variable\", \"y\"), sep = 1) %>% \n  pivot_wider(names_from = \"variable\", values_from = \"value\") %>% \n  group_by(id) %>% \n  mutate(across(c(t, d), list(lag = lag))) %>% \n  ungroup()\nhead(df_tidy)\n## # A tibble: 6 × 7\n##      id      c y           t       d  t_lag   d_lag\n##   <int>  <dbl> <chr>   <dbl>   <dbl>  <dbl>   <dbl>\n## 1     1  0.586 1     -0.546  -1.11   NA     NA     \n## 2     1  0.586 2     -0.853  -1.73   -0.546 -1.11  \n## 3     2  0.709 1      1.14    0.361  NA     NA     \n## 4     2  0.709 2     -0.0673 -1.30    1.14   0.361 \n## 5     3 -0.109 1     -0.584  -0.0822 NA     NA     \n## 6     3 -0.109 2     -0.932   0.535  -0.584 -0.0822\n```\n:::\n\n\nThis is how panel data is typically structured, with rows repeated for each time period. This is good because we can figure out how to structure the weight models and outcome model in a way that uses this structure and compare it to the original `t1`, `d1`, etc. models. \n\nBecause there are only two time periods, the lagged columns here are missing a ton of data (since you can't see what the value is for year 0), but it'll still work.\n\nWith the data like this, we can find the weights. We'll do it both manually and with the **ipw** package.\n\nManually, we need to fit two models (a numerator and denominator) and then take the cumulative product of their probability distributions:\n\n$$\nw = \\prod^t_{t = 1} \\frac{\\phi(T_{it} | T_{i, t-1}, C_i)}{\\phi(T_{it} | T_{i, t-1}, D_{i, t-1}, C_i)}\n$$\n\nHere we go!\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Remove NAs since ipwpoint() will complain\ndf_tidy_sans_na <- df_tidy %>%\n  filter(!is.na(t_lag))\n\n# Manually\n# Numerator is lagged treatment + non-varying confounders\nmodel_num <- lm(t ~ t_lag + c,\n                data = df_tidy_sans_na)\n\n# Denominator is lagged treatment, lagged outcome, time-varying confounders +\n# non-varying confounders\nmodel_denom <- lm(t ~ t_lag + d_lag + c, \n                  data = df_tidy_sans_na)\n\n# Probability distributions\nnum <- dnorm(df_tidy_sans_na$t,\n             predict(model_num),\n             sd(residuals(model_num)))\n\nden <- dnorm(df_tidy_sans_na$t,\n             predict(model_denom),\n             sd(residuals(model_denom)))\n\n# Make num/den fraction and find cumulative product within each id\ndf_weights_manual <- df_tidy_sans_na %>% \n  mutate(weights_no_time = num / den) %>% \n  group_by(id) %>% \n  mutate(ipw = cumprod(weights_no_time)) %>% \n  ungroup()\n\n# Automatically find weights with ipw::ipwpoint()\ntidy_weights_auto <- ipwpoint(\n  exposure = t,\n  family = \"gaussian\", \n  numerator = ~ t_lag + c, \n  denominator = ~ t_lag + d_lag + c, \n  data = as.data.frame(df_tidy_sans_na))\n\ndf_weights_auto <- df_tidy_sans_na %>% \n  mutate(ipw = tidy_weights_auto$ipw.weights)\n```\n:::\n\n\nNow we can use these new weights in the outcome model:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel_lags_manual <- geeglm(d ~ t + t_lag, data = df_weights_manual,\n                            id = id, weights = ipw)\n\nmodel_lags_auto <- geeglm(d ~ t + t_lag, data = df_weights_auto, \n                          id = id, weights = ipw)\n\nresults <- tribble(\n  ~`Method`, ~`T<sub>1</sub> effect`, ~`T<sub>2</sub> effect`,\n  \"True effect\", 0.160, 0.400,\n  \"IPW, original\", filter(tidy(stab_ipw), term == \"t1\")$estimate, filter(tidy(stab_ipw), term == \"t2\")$estimate,\n  \"IPW, lagged, manual\", filter(tidy(model_lags_manual), term == \"t_lag\")$estimate, filter(tidy(model_lags_manual), term == \"t\")$estimate,\n  \"IPW, lagged, automatic\", filter(tidy(model_lags_auto), term == \"t_lag\")$estimate, filter(tidy(model_lags_auto), term == \"t\")$estimate\n) %>% \n  mutate(across(2:3, ~sprintf(\"%.3f\", round(., 3)))) %>% \n  add_row(`T<sub>1</sub> effect` = \"<b>lag(T) effect</b>\", \n          `T<sub>2</sub> effect` = \"<b>T effect</b>\", \n          .after = 2)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table style=\"width:70%; margin-left: auto; margin-right: auto;\" class=\" table table-sm\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Method </th>\n   <th style=\"text-align:left;\"> T<sub>1</sub> effect </th>\n   <th style=\"text-align:left;\"> T<sub>2</sub> effect </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> True effect </td>\n   <td style=\"text-align:left;\"> 0.160 </td>\n   <td style=\"text-align:left;\"> 0.400 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> IPW, original </td>\n   <td style=\"text-align:left;\"> 0.157 </td>\n   <td style=\"text-align:left;\"> 0.421 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> — </td>\n   <td style=\"text-align:left;\"> <b>lag(T) effect</b> </td>\n   <td style=\"text-align:left;\"> <b>T effect</b> </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> IPW, lagged, manual </td>\n   <td style=\"text-align:left;\"> 0.150 </td>\n   <td style=\"text-align:left;\"> 0.441 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> IPW, lagged, automatic </td>\n   <td style=\"text-align:left;\"> 0.150 </td>\n   <td style=\"text-align:left;\"> 0.441 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nThose results aren't identical (I don't know why!), but they're close-ish, so whatever. It worked! Instead of using explicit `t1`, `d1`, etc. columns, we can do the same marginal structural model with just `t` and `d` in a long data frame.\n\n\n## Expansion to multiple-period data\n\nSince that's all working, now we can do something a little/lot trickier—instead of manually specifying $T_1$ and $T_2$, which isn't really easily scalable to more time periods, we'll construct the data more generally for any number of years\n\n### Tricky interdependent data generating process\n\nThe trick here is that we want to have any number of time periods, but also maintain the same DAG relationships. In the small data, these are the two general relationships:\n\n- $\\text{treatment}_t = (0.1 \\cdot \\text{confounder}) + (0.4 \\cdot \\text{depression}_{t-1}) + (0.4 \\cdot \\text{treatment}_{t-1}) + \\text{noise}$\n- $\\text{depression}_t = (0.1 \\cdot \\text{confounder}) + (0.4 \\cdot \\text{treatment}_{t}) + (0.4 \\cdot \\text{depression}_{t-1}) + \\text{noise}$\n\nOr in code:\n\n- `t = (0.1 * c) + (0.4 * lag(d)) + (0.4 * lag(t)) + rnorm(n, 0, sqrt(0.5196))`\n- `d = (0.1 * c) + (0.4 * t) + (0.4 * lag(d)) + rnorm(n, 0, sqrt(0.4582))`\n\nGenerating this data in a tidy **dplyr** way is super tricky, since the `t` and `d` columns are interdependent—the data has to be generated rowwise, but we also have to be able to look back a row to get the lagged values of `t` and `d`. I've seen people like @BlackwellGlynn:2018 get around this by using a `for` loop to build the data, but I have an aversion to for loops in R [since **purrr** exists](https://r4ds.had.co.nz/iteration.html#for-loops-vs.-functionals), so I spent way too much time trying to figure out a **purrr**-based way to do this. Others have tried this (like [this RStudio Community post](https://community.rstudio.com/t/row-wise-iteration-in-a-dataframe-with-interdependent-variables/38778)), and I [asked about it on Twitter](https://twitter.com/andrewheiss/status/1347780639714664448), where I got a few cool solutions using `purrr::accumulate()` and `purrr::reduce()`, like [this fancy `accumutate()` function from Ian Moran](https://twitter.com/ianmoran011/status/1347849678696574977) and [these solutions from Miles McBain](https://gist.github.com/andrewheiss/89ae26a7a4682aff0ee9b7db1e92c326#gistcomment-3587810). \n\nThere are no loops involved in those solutions, but phew that accumulate/reduce syntax is wonky and I can't fully wrap my head around it (plus it makes it hard to carry over non-accumulated variables). So I resorted to a loop. Oooof.\n\nIt works, though! Let's test it on just one ID. We'll generate just one row with `t1`, `t2`, `d1`, and `d2`, and we'll remove the noise from each of the columns:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(12345)\nn <- 1\n\n# Remove all noise so that we can compare this with the function version\ndf_example <- tibble(id = 1:n,\n                     c = rnorm(n, 0, 1)) %>% \n  mutate(t1 = (0.1 * c),\n         d1 = (0.1 * c) + (0.4 * t1),\n         t2 = (0.1 * c) + (0.4 * d1) + (0.4 * t1),\n         d2 = (0.1 * c) + (0.4 * t2) + (0.4 * d1))\ndf_example\n## # A tibble: 1 × 6\n##      id     c     t1     d1    t2    d2\n##   <int> <dbl>  <dbl>  <dbl> <dbl> <dbl>\n## 1     1 0.586 0.0586 0.0820 0.115 0.137\n```\n:::\n\n\nThis isn't tidy data, so technically there are two years here. We'll keep `t1` and `d1` as the initial values for year 1, then generate values for 5 years. If we do this right, the `t` and `d` values for year 2 should be identical to `t2` and `d2` here.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Add a bunch of extra years with empty cells for t and d\ndf_multiple_years_empty <- df_example %>% \n  mutate(y = 1) %>% \n  select(id, y, t = t1, d = d1, c) %>% \n  add_row(y = 2:5) %>% \n  # c doesn't vary across time\n  mutate(id = 1, \n         c = df_example$c[1])\ndf_multiple_years_empty\n## # A tibble: 5 × 5\n##      id     y       t       d     c\n##   <dbl> <dbl>   <dbl>   <dbl> <dbl>\n## 1     1     1  0.0586  0.0820 0.586\n## 2     1     2 NA      NA      0.586\n## 3     1     3 NA      NA      0.586\n## 4     1     4 NA      NA      0.586\n## 5     1     5 NA      NA      0.586\n\n# Now we need to build the interdependent values for t and d with <gasp> a loop\n#\n# The loop is inside this function---it skips the initial row and then\n# iteratively adds new rows. We can't use neat things like lag(t), so instead\n# we use df$t[i - 1]\n# \n# We omit the extra noise for now\ndgp <- function(df) {\n  for (i in 2:nrow(df)) {\n    df$t[i] <- (0.1 * df$c[i]) + (0.4 * df$d[i - 1]) + (0.4 * df$t[i - 1])\n    df$d[i] <- (0.1 * df$c[i]) + (0.4 * df$t[i]) + (0.4 * df$d[i - 1])\n  }\n  \n  df\n}\n\n# Generate all 5 years\ndf_multiple_years_empty %>% \n  dgp()\n## # A tibble: 5 × 5\n##      id     y      t      d     c\n##   <dbl> <dbl>  <dbl>  <dbl> <dbl>\n## 1     1     1 0.0586 0.0820 0.586\n## 2     1     2 0.115  0.137  0.586\n## 3     1     3 0.159  0.177  0.586\n## 4     1     4 0.193  0.207  0.586\n## 5     1     5 0.219  0.229  0.586\n```\n:::\n\n\nIf this worked, the `t` and `d` values for year 2 should be the same as `t2` and `d2` here:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf_example\n## # A tibble: 1 × 6\n##      id     c     t1     d1    t2    d2\n##   <int> <dbl>  <dbl>  <dbl> <dbl> <dbl>\n## 1     1 0.586 0.0586 0.0820 0.115 0.137\n```\n:::\n\n\nThey are!\n\nSince we know it works, let's generate a big dataset for playing with multi-year MSMs, this time with noise:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(1234)\n\n# Make data for the first year\ndf_first_year <- expand_grid(id = 1:2000, y = 1) %>% \n  mutate(c = rnorm(n(), 0, 1),\n         t = (0.1 * c) + rnorm(n(), 0, sqrt(0.99)),\n         d = (0.1 * c) + (0.4 * t) + rnorm(n(), 0, sqrt(0.822)))\ndf_first_year\n## # A tibble: 2,000 × 5\n##       id     y      c        t       d\n##    <int> <dbl>  <dbl>    <dbl>   <dbl>\n##  1     1     1 -1.21  -1.09    -1.43  \n##  2     2     1  0.277 -0.0714  -0.739 \n##  3     3     1  1.08  -0.00174 -0.0686\n##  4     4     1 -2.35   0.952    1.88  \n##  5     5     1  0.429 -1.60     0.0373\n##  6     6     1  0.506 -0.990    0.535 \n##  7     7     1 -0.575 -1.79    -0.889 \n##  8     8     1 -0.547  0.456   -1.14  \n##  9     9     1 -0.564 -0.500    0.386 \n## 10    10     1 -0.890 -1.92    -1.04  \n## # ℹ 1,990 more rows\n\n# Add empty years 2-5\ndf_panel_empty <- df_first_year %>% \n  bind_rows(expand_grid(id = 1:2000, y = 2:5)) %>% \n  arrange(id, y)\nhead(df_panel_empty, 10)\n## # A tibble: 10 × 5\n##       id     y      c       t      d\n##    <int> <dbl>  <dbl>   <dbl>  <dbl>\n##  1     1     1 -1.21  -1.09   -1.43 \n##  2     1     2 NA     NA      NA    \n##  3     1     3 NA     NA      NA    \n##  4     1     4 NA     NA      NA    \n##  5     1     5 NA     NA      NA    \n##  6     2     1  0.277 -0.0714 -0.739\n##  7     2     2 NA     NA      NA    \n##  8     2     3 NA     NA      NA    \n##  9     2     4 NA     NA      NA    \n## 10     2     5 NA     NA      NA\n\n# Add noise to the fancy dgp() function\ndgp <- function(df) {\n  for (i in 2:nrow(df)) {\n    df$t[i] <- (0.1 * df$c[i]) + (0.4 * df$d[i - 1]) + (0.4 * df$t[i - 1]) + rnorm(1, 0, sqrt(0.5196))\n    df$d[i] <- (0.1 * df$c[i]) + (0.4 * df$t[i]) + (0.4 * df$d[i - 1]) + rnorm(1, 0, sqrt(0.4582))\n  }\n  \n  df\n}\n\n# Run dgp() within each id\ndf_panel <- df_panel_empty %>% \n  group_by(id) %>% \n  # This doesn't vary with time, so repeat it across all the years\n  mutate(c = c[1]) %>% \n  # Nest the data into a single cell in each row\n  nest() %>% \n  # Run dgp() on the nested cell (in a column named \"data\")\n  mutate(dgp = map(data, dgp)) %>% \n  select(-data) %>% \n  # Unnest the nested dgp()-ed cells\n  unnest(dgp) %>% \n  # Add some lags\n  mutate(across(c(t, d), list(lag = lag))) %>% \n  ungroup()\nhead(df_panel, 10)\n## # A tibble: 10 × 7\n##       id     y      c       t      d   t_lag  d_lag\n##    <int> <dbl>  <dbl>   <dbl>  <dbl>   <dbl>  <dbl>\n##  1     1     1 -1.21  -1.09   -1.43  NA      NA    \n##  2     1     2 -1.21  -1.11   -1.28  -1.09   -1.43 \n##  3     1     3 -1.21  -1.83   -1.35  -1.11   -1.28 \n##  4     1     4 -1.21  -1.62   -1.20  -1.83   -1.35 \n##  5     1     5 -1.21  -1.62   -0.981 -1.62   -1.20 \n##  6     2     1  0.277 -0.0714 -0.739 NA      NA    \n##  7     2     2  0.277  1.09    0.116 -0.0714 -0.739\n##  8     2     3  0.277  1.43    0.562  1.09    0.116\n##  9     2     4  0.277  0.584  -0.606  1.43    0.562\n## 10     2     5  0.277 -0.881   0.603  0.584  -0.606\n```\n:::\n\n\n### Multiple-period marginal structural models\n\nCool cool cool. We have multi-period data where variables depend on their lagged values and other interdependent columns. Let's build some MSMs!\n\nWe're going to build weights two different ways here. Because the data has a time-series cross-sectional structure (with multiple individuals across multiple years), the weight models need to account for that structure. Everywhere I've seen elsewhere uses generalized estimating equations (GEEs) for these models (and that's what the **ipw** package uses behind the scenes), but I'm a fan of multilevel models, so I'll make weights with both to compare their results.\n\nWe'll use the same equation as before—the cumulative product of the ratio of two probability distributions:\n\n$$\nw = \\prod^t_{t = 1} \\frac{\\phi(T_{it} | T_{i, t-1}, C_i)}{\\phi(T_{it} | T_{i, t-1}, D_{i, t-1}, C_i)}\n$$\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Again, ipw complains about missing values, so get rid of them (i.e. all year 1)\ndf_panel_sans_na <- df_panel %>%\n  filter(!is.na(t_lag)) %>% \n  mutate(y = as.numeric(y))\n\n# Manually\n# Numerator is lagged treatment + non-varying confounders\n# ipw uses GEE models to account for panel structure, so use them here too\nmodel_num_gee <- geeglm(t ~ t_lag + c, \n                        id = id, waves = y, corstr = \"ar1\",\n                        data = df_panel_sans_na)\n\n# But we can also use mixed models with lmer\nmodel_num_multi <- lmer(t ~ t_lag + c + (1 | id),\n                        data = df_panel_sans_na)\n\n# Denominator is lagged treatment, lagged outcome, time-varying confounders +\n# non-varying confounders\nmodel_denom_gee <- geeglm(t ~ t_lag + d_lag + c, \n                          id = id, waves = y, corstr = \"ar1\",\n                          data = df_panel_sans_na)\n\nmodel_denom_multi <- lmer(t ~ t_lag + d_lag + c + (1 | id),\n                          data = df_panel_sans_na)\n\n# Probability distributions\nnum_gee <- dnorm(df_panel_sans_na$t,\n             predict(model_num_gee),\n             sd(residuals(model_num_gee)))\n\nden_gee <- dnorm(df_panel_sans_na$t,\n                 predict(model_denom_gee),\n                 sd(residuals(model_denom_gee)))\n\nnum_multi <- dnorm(df_panel_sans_na$t,\n                   predict(model_num_multi),\n                   sd(residuals(model_num_multi)))\n\nden_multi <- dnorm(df_panel_sans_na$t,\n                   predict(model_denom_multi),\n                   sd(residuals(model_denom_multi)))\n\ndf_panel_weights_manual <- df_panel_sans_na %>% \n  mutate(weights_no_time_gee = num_gee / den_gee,\n         weights_no_time_multi = num_multi / den_multi) %>% \n  group_by(id) %>% \n  mutate(ipw_gee = cumprod(weights_no_time_gee),\n         ipw_multi = cumprod(weights_no_time_multi)) %>% \n  ungroup()\n\n# Automatically with ipwtm()\npanel_weights_auto <- ipwtm(\n  exposure = t,\n  family = \"gaussian\", \n  numerator = ~ t_lag + c, \n  denominator = ~ t_lag + d_lag + c, \n  id = id,\n  timevar = y,\n  type = \"all\",\n  corstr = \"ar1\",\n  data = as.data.frame(df_panel_sans_na))\n\ndf_panel_weights_auto <- df_panel_sans_na %>% \n  mutate(ipw = panel_weights_auto$ipw.weights)\n```\n:::\n\n\nNow we can build the outcome models, using both GEE and multilevel models.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm_manual_gee <- geeglm(d ~ t + t_lag, \n                       data = df_panel_weights_manual,\n                       id = id, waves = y, \n                       weights = ipw_gee)\n\nm_auto_gee <- geeglm(d ~ t + t_lag, \n                     data = df_panel_weights_auto, \n                     id = id, waves = y, \n                     weights = ipw)\n\nm_lmer_manual_gee_wt <- lmer(d ~ t + t_lag + (1 | id), \n                             data = df_panel_weights_manual, \n                             weights = ipw_gee)\n\nm_lmer_auto_gee_wt <- lmer(d ~ t + t_lag + (1 | id), \n                           data = df_panel_weights_auto, \n                           weights = ipw)\n\nm_lmer_manual_multi_wt <- lmer(d ~ t + t_lag + (1 | id), \n                               data = df_panel_weights_manual, \n                               weights = ipw_multi)\n\nresults <- tribble(\n  ~`Method`, ~`Weights`, ~`lag(T) effect`, ~`T effect`,\n  \"True effect\", NA, 0.160, 0.400,\n  \"Panel with GEE\", \"Manual GEE weights\", filter(tidy(m_manual_gee), term == \"t_lag\")$estimate, filter(tidy(m_manual_gee), term == \"t\")$estimate,\n  \"Panel with GEE\", \"Automatic GEE weights\", filter(tidy(m_auto_gee), term == \"t_lag\")$estimate, filter(tidy(m_auto_gee), term == \"t\")$estimate,\n  \"Panel with multilevel model\", \"Manual GEE weights\", filter(tidy(m_lmer_manual_gee_wt), term == \"t_lag\")$estimate, filter(tidy(m_lmer_manual_gee_wt), term == \"t\")$estimate,\n  \"Panel with multilevel model\", \"Automatic GEE weights\", filter(tidy(m_lmer_auto_gee_wt), term == \"t_lag\")$estimate, filter(tidy(m_lmer_auto_gee_wt), term == \"t\")$estimate,\n  \"Panel with multilevel model\", \"Manual multilevel weights\", filter(tidy(m_lmer_manual_multi_wt), term == \"t_lag\")$estimate, filter(tidy(m_lmer_manual_multi_wt), term == \"t\")$estimate\n)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table style=\"width:90%; margin-left: auto; margin-right: auto;\" class=\" table table-sm\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Method </th>\n   <th style=\"text-align:left;\"> Weights </th>\n   <th style=\"text-align:right;\"> lag(T) effect </th>\n   <th style=\"text-align:right;\"> T effect </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> True effect </td>\n   <td style=\"text-align:left;\"> — </td>\n   <td style=\"text-align:right;\"> 0.160 </td>\n   <td style=\"text-align:right;\"> 0.400 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Panel with GEE </td>\n   <td style=\"text-align:left;\"> Manual GEE weights </td>\n   <td style=\"text-align:right;\"> 0.230 </td>\n   <td style=\"text-align:right;\"> 0.429 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Panel with GEE </td>\n   <td style=\"text-align:left;\"> Automatic GEE weights </td>\n   <td style=\"text-align:right;\"> 0.230 </td>\n   <td style=\"text-align:right;\"> 0.429 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Panel with multilevel model </td>\n   <td style=\"text-align:left;\"> Manual GEE weights </td>\n   <td style=\"text-align:right;\"> 0.195 </td>\n   <td style=\"text-align:right;\"> 0.408 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Panel with multilevel model </td>\n   <td style=\"text-align:left;\"> Automatic GEE weights </td>\n   <td style=\"text-align:right;\"> 0.195 </td>\n   <td style=\"text-align:right;\"> 0.408 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Panel with multilevel model </td>\n   <td style=\"text-align:left;\"> Manual multilevel weights </td>\n   <td style=\"text-align:right;\"> 0.196 </td>\n   <td style=\"text-align:right;\"> 0.414 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nPhew.\n\nAll of the models here are relatively close to the true effect for $T_t$! (Though they're all sizably off for $T_{t-1}$, but I don't know why). \n\nImportantly, it seems that mixed models work just fine for both weights and outcome models, which means there's probably no need to use GEE (and this can all be done Bayesianly with `brms()`!). \n\nIt works!\n\n\n## Questions for the future\n\nI still have some lingering things to check (forthcoming in a future blog post):\n\n- `y` isn't any any of the models: weights numerator, weights denominator, or outcome. If I include it in any of the models, the there's perfect fit. That may be because there are no time-varying confounders? I think year might need to be in there somewhere, but I'm not sure. @BlackwellGlynn:2018 include year in the numerator and denominator for weights in their Swank Steinmo replication, but not in their Burgoon replication.\n\n- This example has no time-varying confounders. I need to see how this all works with those.\n\n- This DAG for this example is pretty simple. I need to see what happens when there are *also* direct arrows from $T_{t-1} \\rightarrow T_{t}$ and $D_{t-1} \\rightarrow D_{t}$.\n\n\n## References\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../../../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../../../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}