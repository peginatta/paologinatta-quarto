{
  "hash": "4074899fc148fcbc5e9ecdd1a62bfa93",
  "result": {
    "markdown": "---\ntitle: \"Exploring Pamela Jakiela's simple TWFE diagnostics with R\"\ndate: 2021-08-25\ndescription: \"Use R to explore possible biases that come from differential treatment timing in two-way fixed effects (TWFE) regression models\"\nimage: index_files/figure-html/show-weights-hist-1.png\ncategories:\n  - r\n  - tidyverse\n  - regression\n  - statistics\n  - data visualization\n  - econometrics\n  - panel data\ndoi: 10.59350/yrbym-m0y62\ncitation: true\n---\n\n\n\n\nThe world of econometrics has been roiled over the past couple years with a bunch of new papers showing how two-way fixed effects (TWFE; situations with nested levels of observations, like country-year, state-month, etc.) estimates of causal effects from difference-in-differences-based natural experiments can be biased when treatment is applied at different times. There are a ton of these papers, like @de-ChaisemartindHaultfoeuille:2020, @Goodman-Bacon:2021, @SunAbraham:2020, @CallawaySantAnna:2020, and @BakerLarckerWang:2021. And they're all really technical and scary.\n\nI've been peripherally following these discussions on Twitter, since I teach a class on causal inference and include [a couple sessions and assignments on difference-in-differences approaches](https://evalf21.classes.andrewheiss.com/example/diff-in-diff/), and since I do lots of [research with country-year panel data](https://www.andrewheiss.com/research/articles/chaudhry-heiss-ngos-aid/) (see [all my posts on marginal structural models](https://www.andrewheiss.com/blog/tags/inverse-probability-weighting/) for more on that), but I've admittedly been lost in the mathy details of all these papers and I've been slightly terrified of trying to work through these papers and figuring out what this differential timing bias actually looks like in real life. I'm not a real economist or econometrician (I just teach microeconomics and econometrics lolz), so this world is still pretty intimidating for me.\n\nBut [Pamela Jakiela](https://pjakiela.github.io/) recently posted [a working paper called \"Simple Diagnostics for Two-Way Fixed Effects\"](https://arxiv.org/abs/2103.13229) [@Jakiela:2021] where she presents an easy-to-follow example of all this newfangled TWFE work, so I figured I'd finally officially plunge into this new TWFE world and try to figure out what it all means. Her paper is fantastic—you should read it if you want a quick introduction to the issues of differential timing and TWFE and if you want some easy ways to see how bad these situations might bias causal estimates.\n\nIn the spirit of [Vincent Arel-Bundock](http://arelbundock.com/), who publicly codes through more technical papers to understand them better (see [this](http://arelbundock.com/posts/frontdoor/) or [this](http://arelbundock.com/posts/robustness_values/) or [this](http://arelbundock.com/posts/marginal_structural_models/)), this post is my attempt at translating Jakiela's paper from conceptual math and Stata code into R. Here we go!\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)     # For ggplot2, dplyr, and friends\nlibrary(haven)         # For reading Stata files\nlibrary(fixest)        # One way of doing fixed effects regression\nlibrary(estimatr)      # Another way of doing fixed effects regression\nlibrary(broom)         # For converting model objects to data frames\nlibrary(kableExtra)    # For pretty tables\nlibrary(modelsummary)  # For pretty regression tables\nlibrary(patchwork)     # For combining plots\nlibrary(scales)        # For nice formatting functions\n\n# Custom ggplot theme to make pretty plots\n# Get the font at https://fonts.google.com/specimen/Barlow+Semi+Condensed\ntheme_clean <- function() {\n  theme_minimal(base_family = \"Barlow Semi Condensed\") +\n    theme(panel.grid.minor = element_blank(),\n          plot.title = element_text(face = \"bold\"),\n          axis.title = element_text(family = \"Barlow Semi Condensed Medium\"),\n          strip.text = element_text(family = \"Barlow Semi Condensed\",\n                                    face = \"bold\", size = rel(1), hjust = 0),\n          strip.background = element_rect(fill = \"grey80\", color = NA),\n          plot.caption = element_text(hjust = 0))\n}\n```\n:::\n\n\n## A different way of thinking about OLS coefficients\n\nBefore diving into the issues that come with TWFE estimation (and Jakiela's proposed diagnostics), we first have to think about regression coefficients in a slightly different way (that was completely new to me!)\n\nTo do this, let's make some simulated data to play with. We have two variables: (1) an outcome that ranges from ≈400–2000, and (2) a continuous treatment that ranges from ≈2–70. For the sake of simplicity, we'll pretend that the outcome represents weekly income, and the treatment is some sort of social policy (test scores from some job training program? idk—imagine something neat here). We'll also pretend that this treatment is experimental so we can talk about causation here.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(1234)  # For reproducibility\n\nn_rows <- 500\nfake_data <- tibble(treatment = rbeta(n_rows, shape1 = 3, shape2 = 7)) %>%\n  mutate(treatment = round(treatment * 100)) %>%\n  # Build the outcome based on some baseline level of outcome + a boost in\n  # outcome that happens because of the treatment + some noise\n  mutate(outcome_baseline = rnorm(n_rows, mean = 800, sd = 200),\n         treatment_boost = 10 * treatment,\n         outcome = outcome_baseline + treatment_boost + rnorm(n_rows, 200, 100)) %>%\n  select(outcome, treatment)\n\nhead(fake_data)\n## # A tibble: 6 × 2\n##   outcome treatment\n##     <dbl>     <dbl>\n## 1    514.        13\n## 2   1550.        35\n## 3   1562.        52\n## 4   1037.         4\n## 5   1137.        38\n## 6   1277.        39\n```\n:::\n\n\nFor reference, here's what the distributions of these variables look like, along with the relationship between treatment and outcome:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nhist_out <- ggplot(fake_data, aes(x = outcome)) +\n  geom_histogram(binwidth = 100, color = \"white\",\n                 boundary = 0, fill = \"#FFA615\") +\n  scale_x_continuous(labels = dollar_format()) +\n  labs(title = \"Distribution of outcome\",\n       x = \"Outcome\", y = \"Count\") +\n  coord_cartesian(ylim = c(0, 80)) +\n  theme_clean() +\n  theme(panel.grid.major.x = element_blank())\n\nhist_trt <- ggplot(fake_data, aes(x = treatment)) +\n  geom_histogram(binwidth = 5, color = \"white\",\n                 boundary = 0, fill = \"#A4BD0A\") +\n  labs(title = \"Distribution of treatment\",\n       x = \"Treatment\", y = \"Count\") +\n  coord_cartesian(ylim = c(0, 80)) +\n  theme_clean() +\n  theme(panel.grid.major.x = element_blank())\n\nplot_trt_out <- ggplot(fake_data, aes(x = treatment, y = outcome)) +\n  geom_point(size = 0.75) +\n  geom_smooth(method = \"lm\", color = \"#0599B0\") +\n  scale_y_continuous(labels = dollar_format()) +\n  labs(title = \"Effect of treatment on outcome\",\n       x = \"Treatment\", y = \"Outcome\") +\n  theme_clean()\n\n(hist_out + hist_trt) / plot_spacer() / plot_trt_out +\n  plot_layout(heights = c(0.28, 0.02, 0.7))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/show-fake-data-1.png){fig-align='center' width=75%}\n:::\n:::\n\n\nWe can find the average treatment effect (ATE) of this imaginary program on the outcome using a simple univariate regression model:\n\n$$\n\\color{gray}{\\overbrace{\\color{#FFA615}{Y}}^{\\text{Outcome}}_{\\underbrace{\\color{#FFA615}{i}}_{\\text{An individual}}}} \\color{black}{=} \\color{gray}{\\overbrace{\\color{black}{\\alpha}}^{\\text{Intercept}}} \\color{black}{+} \\color{gray}{\\underbrace{\\color{#0599B0}{\\beta}}_{\\text{ATE}}} \\color{gray}{\\overbrace{\\color{#A4BD0A}{D_i}}^{\\text{Treatment}}} \\color{black}{+} \\color{gray}{\\overbrace{\\color{black}{\\epsilon_i}}^{\\text{Error}}}\n$$\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel_effect <- lm(outcome ~ treatment, data = fake_data)\ntidy(model_effect)\n## # A tibble: 2 × 5\n##   term        estimate std.error statistic   p.value\n##   <chr>          <dbl>     <dbl>     <dbl>     <dbl>\n## 1 (Intercept)  1001.      22.5        44.6 5.70e-176\n## 2 treatment       9.69     0.672      14.4 1.26e- 39\n```\n:::\n\n\nThis is just regular old OLS regression. Based on this model, a 1-unit increase in treatment causes a \\$9.69 increase in the outcome. Lovely.\n\n@Jakiela:2021 [4] shows an alternate way of calculating $\\beta$, though, based on the [Frisch-Waugh-Lovell theorem](https://en.wikipedia.org/wiki/Frisch%E2%80%93Waugh%E2%80%93Lovell_theorem), which is an econometrics idea that I've never heard of (since I'm defs not an economist). According to this theorem, we can rewrite the OLS estimate of $\\beta$ based on the residuals ($\\tilde{D}_i$) of a model that predicts treatment:\n\n$$\n\\color{#0599B0}{\\beta}\\ \\color{black}{=}\\ \\sum_i \\color{#FFA615}{Y_i} \\color{black}\\left( \\frac{\\color{#353D03}{\\tilde{D}_i}}{\\sum_i \\color{#353D03}{\\tilde{D}_i}^2} \\right)\n$$\n\nSince this is a univariate model, the residuals here are really just the deviations from the average value of the treatment, or $D_i - \\bar{D}$. We can confirm this by running an intercept-only model and comparing it to $D_i - \\bar{D}$:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntrt_resid <- lm(treatment ~ 1, data = fake_data)\n\nfake_data_resid <- fake_data %>%\n  mutate(treatment_resid = residuals(trt_resid)) %>%\n  mutate(mean_treat = mean(treatment),\n         diff = treatment - mean_treat)\n\nhead(fake_data_resid)\n## # A tibble: 6 × 5\n##   outcome treatment treatment_resid mean_treat   diff\n##     <dbl>     <dbl>           <dbl>      <dbl>  <dbl>\n## 1    514.        13          -17.2        30.2 -17.2 \n## 2   1550.        35            4.82       30.2   4.82\n## 3   1562.        52           21.8        30.2  21.8 \n## 4   1037.         4          -26.2        30.2 -26.2 \n## 5   1137.        38            7.82       30.2   7.82\n## 6   1277.        39            8.82       30.2   8.82\n```\n:::\n\n\nThe `treatment_resid` and `diff` columns here are identical. Now that we have $\\tilde{D}_i$, we can use that fancy rewritten formula and calculate $\\beta$:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfake_data_resid %>%\n  summarize(beta = sum(outcome * (treatment_resid / sum(treatment_resid^2))))\n## # A tibble: 1 × 1\n##    beta\n##   <dbl>\n## 1  9.69\n```\n:::\n\n\nWHAAAAAT it's the same ATE that we get from running a regular OLS model! That's magical!\n\nThe reason Jakiela reparameterizes $\\beta$ this way is because looking at residuals like this creates inherent weights for each observation. Essentially, $\\beta$ is a **weighted sum of the outcome variable**, with the weights calculated with $\\frac{\\tilde{D}_{it}}{\\sum_{it} \\tilde{D}_{it}^2}$, or `(treatment_resid / sum(treatment_resid^2))`. We can calculate the weights for each observation:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfake_data_with_weights <- fake_data_resid %>%\n  mutate(treatment_weight = treatment_resid / sum(treatment_resid^2))\nhead(fake_data_with_weights)\n## # A tibble: 6 × 6\n##   outcome treatment treatment_resid mean_treat   diff treatment_weight\n##     <dbl>     <dbl>           <dbl>      <dbl>  <dbl>            <dbl>\n## 1    514.        13          -17.2        30.2 -17.2        -0.000168 \n## 2   1550.        35            4.82       30.2   4.82        0.0000471\n## 3   1562.        52           21.8        30.2  21.8         0.000213 \n## 4   1037.         4          -26.2        30.2 -26.2        -0.000255 \n## 5   1137.        38            7.82       30.2   7.82        0.0000764\n## 6   1277.        39            8.82       30.2   8.82        0.0000861\n```\n:::\n\n\nIn this case, given that this is overly perfect simulated data, the weights are really small. In theory, the weights should sum up to 0. Let's check that really quick:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfake_data_with_weights %>%\n  summarize(total_weights = sum(treatment_weight))\n## # A tibble: 1 × 1\n##   total_weights\n##           <dbl>\n## 1     -4.61e-19\n```\n:::\n\n\nWe can visualize the distribution of weights too:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(fake_data_with_weights, aes(x = treatment_weight)) +\n  geom_histogram(binwidth = 0.00005, color = \"white\",\n                 boundary = 0, fill = \"#F6C848\") +\n  geom_vline(xintercept = 0, color = \"#FF2E00\", linewidth = 1) +\n  labs(x = \"Residualized treatment weight\", y = \"Count\") +\n  scale_x_continuous(labels = comma_format()) +\n  theme_clean() +\n  theme(panel.grid.major.x = element_blank())\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/show-weights-fake-data-1.png){fig-align='center' width=75%}\n:::\n:::\n\n\nThere's a pattern to which observations get positive or negative weights. According to @Jakiela:2021 [p. 4],\n\n> As in any univariate OLS regression of an outcome on a continuous measure of treatment intensity, observations with below mean treatment intensity receive negative weight, and may be thought of as part of the comparison group.\n\nSince treatment here is continuous, there's no clear division between treatment and control groups, so mathematically, that threshold becomes the average value of treatment: observations where the treatment value is less than the average (or $D_i < \\bar{D}$) receive negative weight and can conceptually be considered part of the control/comparison group, while observations where $D_i > \\bar{D}$ are in the treatment group. That's apparent in the data too. Look at the first few rows of `fake_data_with_weights` above—observations where `treatment_resid` is negative have negative weights.\n\n## Residualized weights with TWFE models\n\nThis idea of weighting the outcome variable by treatment status (with treated units getting positive weight and untreated units getting negative weight) is central to the rest of Jakiela's argument and diagnostics (as well as all the other neat new diff-in-diff papers). Fundamentally, the main reason TWFE estimates get weird and biased with differently-timed treatments is because of issues with weights—in TWFE settings, treated observations often get negative weights and vice versa. This isn't always bad, and Jakiela explains why and when it's okay. That's essentially the whole point of her paper—she provides diagnostics to help determine if there are serious issues with these residualized treatment weights.\n\n### Load and clean data\n\nTo demonstrate issues with TWFE models, weights, and differential timing, Jakiela looks at the effect of eliminating primary school fees on school enrollment in 15 African countries, based on data from the World Bank. You can get [her data and Stata code at GitHub](https://pjakiela.github.io/TWFE/). First let's load the data and clean it up a little.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfpe_raw <- read_dta(\"WDI-FPE-data.dta\")\n\n# Remove rows where primary school enrollment is missing\nfpe_primary <- fpe_raw %>%\n  filter(!is.na(primary))\n\n# Remove rows where secondary school enrollment is missing\nfpe_secondary <- fpe_raw %>%\n  filter(!is.na(secondary))\n\nhead(fpe_primary)\n## # A tibble: 6 × 8\n##    year country ccode primary    id secondary fpe_year treatment\n##   <dbl> <chr>   <chr>   <dbl> <dbl>     <dbl>    <dbl>     <dbl>\n## 1  1981 Benin   BEN      60.3     2      15.5     2006         0\n## 2  1982 Benin   BEN      64.7     2      18.5     2006         0\n## 3  1983 Benin   BEN      66.2     2      21.2     2006         0\n## 4  1984 Benin   BEN      64.2     2      20.1     2006         0\n## 5  1985 Benin   BEN      64.3     2      19.0     2006         0\n## 6  1986 Benin   BEN      62.4     2      16.3     2006         0\n```\n:::\n\n\nWe have 8 columns to work with:\n\n- `year`: The year of the observation\n- `country` & `ccode` & `id`: The country name, ISO3 country code, and id number for each country (Stata apparently struggles with string-based variables, so `id` works better as a country identifier there)\n- `primary`: Gross enrollment in primary schools\n- `secondary`: Gross enrollment in secondary schools\n- `fpe_year`: Year the country eliminated fees for primary schools\n- `treatment`: Indicator variable that is `1` when `year > fpe_year` and `0` otherwise\n\n### Model specification\n\nWe can estimate the causal effect of eliminating primary school fees (`treatment`) on primary and secondary school enrollment (`primary` and `secondary`) treatment with a TWFE diff-in-diff model:\n\n$$\n\\color{gray}{\\overbrace{\\color{#FFA615}{Y}}^{\\text{Outcome}}_{\\underbrace{\\color{#FFA615}{it}}_{\\substack{i: \\text{ country} \\\\ t: \\text{ year}}}}} \\color{black} = \\color{gray}{\\overbrace{\\color{black}{\\alpha}}^{\\text{Intercept}}} + \\color{gray}{\\overbrace{\\color{black}{\\lambda_i}}^{\\substack{\\text{Country} \\\\ \\text{fixed} \\\\ \\text{effects}}}} + \\color{gray}{\\overbrace{\\color{black}{\\gamma_t}}^{\\substack{\\text{Year} \\\\ \\text{fixed} \\\\ \\text{effects}}}} + \\color{gray}{\\underbrace{\\color{#0599B0}{\\beta}}_{\\text{ATE}}} \\color{gray}{\\overbrace{\\color{#A4BD0A}{D_{it}}}^{\\text{Treatment}}} + \\color{gray}{\\overbrace{\\color{black}{\\epsilon_{it}}}^{\\text{Error}}}\n$$\n\nOr without all the annotations:\n\n$$\n\\color{#FFA615}{Y_{it}} \\color{black}{\\ = \\alpha + \\lambda_i + \\gamma_t +} \\color{#0599B0}{\\beta} \\color{#A4BD0A}{D_{it}} \\color{black}{\\ + \\epsilon_{it}}\n$$\n\n### TWFE models with R\n\nThere are a few different ways to do fixed effects regression with clustered robust standard errors in R. In Stata you do this:\n\n```stata\nreg primary treatment i.year i.id, cluster(id)\n```\n\nIn R, you can use the standard `lm()` function, but it treats country and year as regular explanatory variables, so it includes them in the results from `summary()` or `tidy()`. If you don't want overly long and detailed results tables, you have to filter those results out.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel_lm <- lm(primary ~ treatment + country + factor(year),\n               data = fpe_primary)\n\ntidy(model_lm) %>%\n  filter(!str_detect(term, \"country\"), !str_detect(term, \"year\"))\n## # A tibble: 2 × 5\n##   term        estimate std.error statistic  p.value\n##   <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n## 1 (Intercept)     72.4      4.63     15.6  4.23e-44\n## 2 treatment       20.4      2.75      7.43 5.82e-13\nglance(model_lm)\n## # A tibble: 1 × 12\n##   r.squared adj.r.squared sigma statistic   p.value    df logLik   AIC   BIC deviance\n##       <dbl>         <dbl> <dbl>     <dbl>     <dbl> <dbl>  <dbl> <dbl> <dbl>    <dbl>\n## 1     0.768         0.742  14.7      29.8 1.30e-110    49 -1985. 4073. 4287.   94828.\n## # ℹ 2 more variables: df.residual <int>, nobs <int>\n```\n:::\n\n\nThese observations are clustered by country, so we should probably [cluster our standard errors to capture within-country errors](https://theeffectbook.net/ch-StatisticalAdjustment.html#your-standard-errors-are-probably-wrong). Using `lm()` doesn't let you automatically create robust or clustered standard errors. You can use `lmtest::coeftest()` to do that after the fact, though. We can copy Stata's standard errors precisely if we (1) specify the variance-covariance matrix using the `vcovCl()` function from the **sandwich** library, and (2) specify the degrees of freedom to use, based on the number of countries in the data, minus 1.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf_primary <- fpe_primary %>% distinct(country) %>% nrow()\n\nmodel_lm_clustered <- lmtest::coeftest(model_lm,\n                                       vcov = sandwich::vcovCL,\n                                       cluster = ~country,\n                                       df = df_primary - 1,\n                                       # Keep original model so modelsummary shows R2\n                                       save = TRUE)\n\ntidy(model_lm_clustered) %>%\n  filter(!str_detect(term, \"country\"), !str_detect(term, \"year\"))\n## # A tibble: 2 × 5\n##   term        estimate std.error statistic       p.value\n##   <chr>          <dbl>     <dbl>     <dbl>         <dbl>\n## 1 (Intercept)     72.4      5.83     12.4  0.00000000601\n## 2 treatment       20.4      9.12      2.24 0.0418\n```\n:::\n\n\nYou can also use fancier regression functions that can handle fixed effects more systematically. The `lm_robust()` function from [the **estimatr** package](https://declaredesign.org/r/estimatr/) works really well for defining special fixed effects that are automatically omitted from results tables *and* returning robust and optionally clustered standard errors:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel_lm_robust <- lm_robust(primary ~ treatment,\n                             fixed_effects = ~ country + year,\n                             data = fpe_primary,\n                             clusters = country, se_type = \"stata\")\n\ntidy(model_lm_robust)\n##        term estimate std.error statistic p.value conf.low conf.high df outcome\n## 1 treatment     20.4      9.12      2.24  0.0418    0.867        40 14 primary\nglance(model_lm_robust)\n##   r.squared adj.r.squared statistic p.value df.residual nobs se_type\n## 1     0.768         0.742        NA      NA          14  490   stata\n```\n:::\n\n\nThe `feols()` function from [the **fixest** package](https://lrberge.github.io/fixest/) also works well, though you need to change one of the default settings to get the same SEs as Stata when you have a small sample with nested fixed effects like we have here. By default, `feols()` will nest the fixed effect errors (which is also what [Stata's `reghdfe` package](http://scorreia.com/software/reghdfe/) does), but you can tell it to use the full set of country and year fixed effect errors with the `dof` argument (thanks to [Grant McDermott](https://grantmcdermott.com/) for pointing this out!):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel_feols <- feols(primary ~ treatment | country + year,\n                     data = fpe_primary,\n                     cluster = ~ country,\n                     dof = dof(fixef.K = \"full\"))\n## Warning in dof(fixef.K = \"full\"): The function 'dof' is deprecated. Please use function\n## 'ssc' instead.\n## Warning: feols(fml = pri...: dof is not a valid argument for function feols.\ntidy(model_feols)\n## # A tibble: 1 × 5\n##   term      estimate std.error statistic p.value\n##   <chr>        <dbl>     <dbl>     <dbl>   <dbl>\n## 1 treatment     20.4      8.98      2.28  0.0391\nglance(model_feols)\n## # A tibble: 1 × 9\n##   r.squared adj.r.squared within.r.squared pseudo.r.squared sigma  nobs   AIC   BIC logLik\n##       <dbl>         <dbl>            <dbl>            <dbl> <dbl> <int> <dbl> <dbl>  <dbl>\n## 1     0.768         0.742            0.111               NA  14.7   490 4071. 4280. -1985.\n```\n:::\n\n\nWe can show these all in a side-by-side table using [the **modelsummary** package](https://vincentarelbundock.github.io/modelsummary/). Conveniently, `modelsummary()` also lets you [adjust standard errors on the fly](https://grantmcdermott.com/better-way-adjust-SEs/) with the `vcov` argument, so we could theoretically handle all the clustering here instead of inside `lmtest::coeftest()`, `lm_robust()`, or `feols()`. But since we already specified the clusters above, we'll just use those.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Look at secondary schools too\nmodel_lm_sec <- lm(secondary ~ treatment + country + factor(year),\n                   data = fpe_secondary)\n\ndf_secondary <- fpe_secondary %>% distinct(country) %>% nrow()\n\nmodel_lm_clustered_sec <- lmtest::coeftest(model_lm_sec,\n                                           vcov = sandwich::vcovCL,\n                                           cluster = ~country,\n                                           df = df_secondary - 1,\n                                           save = TRUE)\n\nmodel_lm_robust_sec <- lm_robust(secondary ~ treatment,\n                                 fixed_effects = ~ country + year,\n                                 data = fpe_secondary,\n                                 clusters = country, se_type = \"stata\")\n\nmodel_feols_sec <- feols(secondary ~ treatment | country + year,\n                         data = fpe_secondary,\n                         cluster = ~ country,\n                         dof = dof(fixef.K = \"full\"))\n\n# Define the goodness-of-fit stats to include\ngof_stuff <- tribble(\n  ~raw, ~clean, ~fmt,\n  \"nobs\", \"N\", 0,\n  \"r.squared\", \"R²\", 3\n)\n\n# Define extra rows at the end of the table\nextra_rows <- tribble(\n  ~term, ~a, ~b, ~c, ~d, ~e, ~f,\n  \"Country fixed effects\", \"•\", \"•\", \"•\", \"•\", \"•\", \"•\",\n  \"Year fixed effects\", \"•\", \"•\", \"•\", \"•\", \"•\", \"•\"\n)\n\nmodelsummary(list(\"<code>lm()</code>\" = model_lm_clustered,\n                  \"<code>lm_robust()</code>\" = model_lm_robust,\n                  \"<code>feols()</code>\" = model_feols,\n                  \"<code>lm()</code>\" = model_lm_clustered_sec,\n                  \"<code>lm_robust()</code>\" = model_lm_robust_sec,\n                  \"<code>feols()</code>\" = model_feols_sec),\n             coef_rename = c(\"treatment\" = \"Treatment\"),\n             estimate = \"{estimate}\",\n             statistic = c(\"s.e. = {std.error}\", \"p = {p.value}\"),\n             coef_omit = \"^country|^factor|Intercept\",\n             gof_map = gof_stuff,\n             add_rows = extra_rows,\n             escape = FALSE, output = \"kableExtra\") %>%\n  add_header_above(c(\" \" = 1, \"Primary enrollment\" = 3, \"Secondary enrollment\" = 3)) %>%\n  kable_styling(htmltable_class = \"table table-sm\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table table-sm\" style=\"width: auto !important; margin-left: auto; margin-right: auto; margin-left: auto; margin-right: auto;\">\n <thead>\n<tr>\n<th style=\"empty-cells: hide;border-bottom:hidden;\" colspan=\"1\"></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"3\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">Primary enrollment</div></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"3\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">Secondary enrollment</div></th>\n</tr>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:center;\"> <code>lm()</code> </th>\n   <th style=\"text-align:center;\"> <code>lm_robust()</code> </th>\n   <th style=\"text-align:center;\"> <code>feols()</code> </th>\n   <th style=\"text-align:center;\"> <code>lm()</code>  </th>\n   <th style=\"text-align:center;\"> <code>lm_robust()</code>  </th>\n   <th style=\"text-align:center;\"> <code>feols()</code>  </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Treatment </td>\n   <td style=\"text-align:center;\"> 20.428 </td>\n   <td style=\"text-align:center;\"> 20.428 </td>\n   <td style=\"text-align:center;\"> 20.428 </td>\n   <td style=\"text-align:center;\"> −0.468 </td>\n   <td style=\"text-align:center;\"> −0.468 </td>\n   <td style=\"text-align:center;\"> −0.468 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> s.e. = 9.120 </td>\n   <td style=\"text-align:center;\"> s.e. = 9.120 </td>\n   <td style=\"text-align:center;\"> s.e. = 8.979 </td>\n   <td style=\"text-align:center;\"> s.e. = 3.081 </td>\n   <td style=\"text-align:center;\"> s.e. = 3.081 </td>\n   <td style=\"text-align:center;\"> s.e. = 3.016 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;box-shadow: 0px 1.5px\">  </td>\n   <td style=\"text-align:center;box-shadow: 0px 1.5px\"> p = 0.042 </td>\n   <td style=\"text-align:center;box-shadow: 0px 1.5px\"> p = 0.026 </td>\n   <td style=\"text-align:center;box-shadow: 0px 1.5px\"> p = 0.039 </td>\n   <td style=\"text-align:center;box-shadow: 0px 1.5px\"> p = 0.881 </td>\n   <td style=\"text-align:center;box-shadow: 0px 1.5px\"> p = 0.879 </td>\n   <td style=\"text-align:center;box-shadow: 0px 1.5px\"> p = 0.879 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> N </td>\n   <td style=\"text-align:center;\"> 490 </td>\n   <td style=\"text-align:center;\"> 490 </td>\n   <td style=\"text-align:center;\"> 490 </td>\n   <td style=\"text-align:center;\"> 369 </td>\n   <td style=\"text-align:center;\"> 369 </td>\n   <td style=\"text-align:center;\"> 369 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> R² </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\"> 0.768 </td>\n   <td style=\"text-align:center;\"> 0.768 </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\"> 0.942 </td>\n   <td style=\"text-align:center;\"> 0.942 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Country fixed effects </td>\n   <td style=\"text-align:center;\"> • </td>\n   <td style=\"text-align:center;\"> • </td>\n   <td style=\"text-align:center;\"> • </td>\n   <td style=\"text-align:center;\"> • </td>\n   <td style=\"text-align:center;\"> • </td>\n   <td style=\"text-align:center;\"> • </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Year fixed effects </td>\n   <td style=\"text-align:center;\"> • </td>\n   <td style=\"text-align:center;\"> • </td>\n   <td style=\"text-align:center;\"> • </td>\n   <td style=\"text-align:center;\"> • </td>\n   <td style=\"text-align:center;\"> • </td>\n   <td style=\"text-align:center;\"> • </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nAll these models show the same result: **eliminating primary school fees caused primary school enrollment to increase by 20.4 percentage points.** That's astounding! Removing these fees doesn't have any effect on secondary enrollment though.\n\n\n### TWFE estimate with residualized treatment weights\n\nThese regressions are simple enough to run with `lm()` or `lm_robust()`, but there's an issue with differential timing here. These 15 countries each passed laws eliminating fees in different years:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot_fpe_start <- fpe_raw %>%\n  filter(year == fpe_year) %>%\n  arrange(fpe_year, country) %>%\n  mutate(country = fct_inorder(country))\n\nggplot(plot_fpe_start, aes(y = fct_rev(country))) +\n  geom_segment(aes(x = fpe_year, xend = 2015, yend = country),\n               size = 3, color = \"#D6EB52\") +\n  geom_text(aes(x = fpe_year + 0.2), label = \"▶\", family = \"Arial Unicode MS\",\n            size = 8, color = \"#A4BD0A\") +\n  labs(x = \"Year free primary education implemented\", y = NULL) +\n  theme_clean()\n## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n## ℹ Please use `linewidth` instead.\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/show-fpe-start-1.png){fig-align='center' width=75%}\n:::\n:::\n\n\nThis timing could cause problems. To see these issues, let's calculate the ATE ($\\beta$) with that fancy schmancy Frisch-Waugh-Lovell theorem with residualized treatment weights. There's one key difference here when calculating the residuals though. With the simple model earlier, the treatment residuals were just $D_i - \\bar{D}$, or the residuals from `lm(treatment ~ 1)`. In TWFE situations, though, treatment residuals need to account for both country and year fixed effects, or `lm(treatment ~ country + year)`:\n\n$$\n\\color{#0599B0}{\\beta^{\\text{TWFE}}} \\color{black}{= \\sum_{it}} \\color{#FFA615}{Y_{it}} \\color{black} \\left( \\frac{\\color{#353D03}{\\tilde{D}_{it}}}{\\sum_{it} \\color{#353D03}{\\tilde{D}_{it}}^2} \\right)\n$$\n\nOr, with code:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntrt_resid_primary <- lm(treatment ~ country + factor(year), data = fpe_primary)\ntrt_resid_secondary <- lm(treatment ~ country + factor(year), data = fpe_secondary)\n\nfpe_primary_weights <- fpe_primary %>%\n  mutate(treatment_resid = residuals(trt_resid_primary)) %>%\n  mutate(treatment_weight = treatment_resid / sum(treatment_resid^2))\n\nfpe_secondary_weights <- fpe_secondary %>%\n  mutate(treatment_resid = residuals(trt_resid_secondary)) %>%\n  mutate(treatment_weight = treatment_resid / sum(treatment_resid^2))\n\nfpe_primary_weights %>%\n  summarize(twfe_beta_primary = sum(primary * treatment_weight))\n## # A tibble: 1 × 1\n##   twfe_beta_primary\n##               <dbl>\n## 1              20.4\n\nfpe_secondary_weights %>%\n  summarize(twfe_beta_secondary = sum(secondary * treatment_weight))\n## # A tibble: 1 × 1\n##   twfe_beta_secondary\n##                 <dbl>\n## 1              -0.468\n```\n:::\n\n\nWhoa! It still works this way. This still blows my mind every time.\n\n\n## Jakiela's diagnostics\n\nHowever, because of the differential treatment timing, there are some issues with weighting. Remember from the simple example with fake data that observations in the treatment group typically have positive treatment weights, while those in the comparison/control group have negative weights. With TWFE, some observations' weights switch directions. There are systematic reasons for this. According to @Jakiela:2021 [p. 5], negative weights in treated observations are more likely in (1) early adopter countries, since the country-level treatment mean is high, and (2) later years, since the year-level treatment mean is higher. \n\nHaving negative weights on treated observations isn't necessarily bad! It's often just a mathematical artefact, and if you have (1) enough never-treated observations and (2) enough pre-treatment data, and if (3) the treatment effects are homogenous across all countries, it won't be a problem. But if you don't have enough data, your results will be biased and distorted for later years and for early adopters.\n\nStarting in section 3 of her paper, Jakiela presents a set of diagnostics to see how bad these distortions might be. We need to answer two questions:\n\n1. Do any treated units get negative weight when calculating $\\beta^{\\text{TWFE}}$? Check this by looking at the weights\n2. Can we reject the hypothesis that the treatment effects are homogenous? Check this by looking at the relationship between $\\tilde{Y}_{it}$ and $\\tilde{D}_{it}$. The slope shouldn't be different.\n\n### 3.1: Do treated observations receive negative weights?\n\nFor this first diagnostic, we need to investigate patterns in the residualized weights. Some of the treated country-year observations have negative weight:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Total treated in primary data\nn_treated_primary <- fpe_primary_weights %>%\n  filter(treatment == 1) %>%\n  nrow()\n\n# Total treated in secondary data\nn_treated_secondary <- fpe_secondary_weights %>%\n  filter(treatment == 1) %>%\n  nrow()\n\n# Negatively weighted treated observations in the primary data\nn_treated_negative_primary <- fpe_primary_weights %>%\n  filter(treatment_weight < 0 & treatment == 1) %>%\n  nrow()\n\nn_treated_negative_primary\n## [1] 50\nn_treated_negative_primary / n_treated_primary\n## [1] 0.259\n\n# Negatively weighted treated observations in the secondary data\nn_treated_negative_secondary <- fpe_secondary_weights %>%\n  filter(treatment_weight < 0 & treatment == 1) %>%\n  nrow()\n\nn_treated_negative_secondary\n## [1] 36\nn_treated_negative_secondary / n_treated_secondary\n## [1] 0.261\n```\n:::\n\n\nRoughly a quarter of the treated observations in both the primary and secondary enrollment data are negatively weighted. That might be bad.\n\nWe can look at the distribution of these weights too:\n\n\n::: {.cell .column-page-inset-right layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nplot_weights_primary <- fpe_primary_weights %>%\n  mutate(treatment_fct = factor(treatment, labels = c(\"Untreated\", \"Treated\"), ordered = TRUE)) %>%\n  mutate(oh_no = (treatment == 1 & treatment_weight < 0) | (treatment == 0 & treatment_weight > 0))\n\nplot_weights_secondary <- fpe_secondary_weights %>%\n  mutate(treatment_fct = factor(treatment, labels = c(\"Untreated\", \"Treated\"), ordered = TRUE)) %>%\n  mutate(oh_no = (treatment == 1 & treatment_weight < 0) | (treatment == 0 & treatment_weight > 0))\n\nhist_primary <- ggplot(plot_weights_primary,\n                       aes(x = treatment_weight, fill = treatment_fct, alpha = oh_no)) +\n  geom_histogram(binwidth = 0.002, color = \"white\", boundary = 0,\n                 position = position_identity()) +\n  geom_vline(xintercept = 0, color = \"#FF4136\", size = 0.5) +\n  scale_alpha_manual(values = c(0.6, 1)) +\n  scale_fill_viridis_d(option = \"rocket\", begin = 0.2, end = 0.8) +\n  labs(x = \"Residualized treatment\", y = \"Count\",\n       title = \"Primary school enrollment\") +\n  guides(fill = \"none\", alpha = \"none\") +\n  facet_wrap(vars(treatment_fct), ncol = 1) +\n  theme_clean()\n\nhist_secondary <- ggplot(plot_weights_secondary,\n                         aes(x = treatment_weight, fill = treatment_fct, alpha = oh_no)) +\n  geom_histogram(binwidth = 0.002, color = \"white\", boundary = 0,\n                 position = position_identity()) +\n  geom_vline(xintercept = 0, color = \"#FF4136\", size = 0.5) +\n  scale_alpha_manual(values = c(0.6, 1)) +\n  scale_fill_viridis_d(option = \"rocket\", begin = 0.2, end = 0.8) +\n  labs(x = \"Residualized treatment\", y = \"Count\",\n       title = \"Secondary school enrollment\") +\n  guides(fill = \"none\", alpha = \"none\") +\n  facet_wrap(vars(treatment_fct), ncol = 1) +\n  theme_clean()\n\nhist_primary + hist_secondary\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/show-weights-hist-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\nThese histograms confirm the proportions we found earlier—about 25% of the treated observations have negative weights.\n\nWhich treated country-years are getting these negative weights, though? According to Jakiela, early adopters and later years are more likely to have this switch happen. Let's make another plot:\n\n\n::: {.cell .column-page-inset-right layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nplot_waffle_primary <- fpe_primary_weights %>%\n  mutate(weight_fill = case_when(\n    treatment_resid < 0 & treatment ~ \"Treatment observations, negative weight\",\n    treatment_resid > 0 & treatment ~ \"Treatment observations, positive weight\",\n    !treatment ~ \"Comparison observations\"\n  )) %>%\n  arrange(desc(fpe_year), desc(country)) %>%\n  mutate(country = fct_inorder(country)) %>%\n  mutate(weight_fill = fct_inorder(weight_fill))\n\nplot_waffle_secondary <- fpe_secondary_weights %>%\n  mutate(weight_fill = case_when(\n    treatment_resid < 0 & treatment ~ \"Treatment observations, negative weight\",\n    treatment_resid > 0 & treatment ~ \"Treatment observations, positive weight\",\n    !treatment ~ \"Comparison observations\"\n  )) %>%\n  arrange(desc(fpe_year), desc(country)) %>%\n  mutate(country = fct_inorder(country)) %>%\n  mutate(weight_fill = fct_inorder(weight_fill))\n\nwaffle_primary <- ggplot(plot_waffle_primary,\n                         aes(x = year, y = country, fill = weight_fill)) +\n  geom_tile(color = \"white\", size = 0.5) +\n  scale_fill_manual(values = c(\"grey50\", \"#0074D9\", \"#FF4136\"),\n                    guide = guide_legend(reverse = TRUE),\n                    name = NULL) +\n  scale_x_continuous(expand = expansion(add = 0.5),\n                     breaks = seq(1980, 2015, 5)) +\n  labs(x = NULL, y = NULL, title = \"Primary school enrollment\") +\n  coord_equal() +\n  theme_clean() +\n  theme(legend.position = \"bottom\",\n        panel.grid = element_blank(),\n        legend.key.size = unit(0.8, \"lines\"))\n\nwaffle_secondary <- ggplot(plot_waffle_secondary,\n                         aes(x = year, y = country, fill = weight_fill)) +\n  geom_tile(color = \"white\", size = 0.5) +\n  scale_fill_manual(values = c(\"grey50\", \"#0074D9\", \"#FF4136\"),\n                    guide = guide_legend(reverse = TRUE),\n                    name = NULL) +\n  scale_x_continuous(expand = expansion(add = 0.5),\n                     breaks = seq(1980, 2015, 5)) +\n  labs(x = NULL, y = NULL, title = \"Secondary school enrollment\") +\n  coord_equal() +\n  theme_clean() +\n  theme(legend.position = \"bottom\",\n        panel.grid = element_blank(),\n        legend.key.size = unit(0.8, \"lines\"))\n\nwaffle_primary / waffle_secondary\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/show-weight-waffle-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\nAnd that is indeed the case! Malawi, Ethiopia, Ghana, Uganda, and Cameroon all eliminated fees before 2000, and they start getting negative weights after 2005. \n\n\n### 3.2: Testing the homogeneity assumption directly\n\nWe thus have issues with negative weighting here for early adopting countries and later country-years. However, as long as the treatment effects are homogenous—or that the elimination of school fees has the same effect across time and country—this negative weighting isn't an issue. If treatment effects are heterogenous—especially if the effects change over time within treated countries—the TWFE estimate will be severely biased.\n\nJakiela's second diagnostic tests this assumption of homogeneity based on the mathematical relationship between the residuals of the outcome variable (`$\\tilde{Y}_{it}$`) and the residuals of the treatment variable (`$\\tilde{D}_{it}$`). Essentially, if there's no difference in slopes across treated and untreated observations in a regression of `$\\tilde{Y}_{it} = \\tilde{D}_{it}$`, there's no evidence for heterogeneity and all is well.\n\nThis wasn't intuitive for me since I'm not a real econometrician, so I had to dig into the math to try to wrap my head around it, and I'm still only like 80% sure I've got it :) \n\nWe can think of the outcome $Y_{it}$ as a combination of three different moving parts: (1) an initial baseline value for each country, or $\\mu_{i}$, (2) a constant change in each additional year in the absence of treatment (i.e. what would naturally happen over time regardless of an intervention), or $\\eta_t$, and (3) a homogenous treatment effect, or $\\delta$ (doesn't have subscripts for $i$ or $t$—it's the same across year and country):\n\n$$\n\\color{gray}{\\overbrace{\\color{#FFA615}{Y_{it}}}^{\\text{Outcome}}} = \\color{gray}{\\overbrace{\\color{black}{\\mu_i}}^{\\substack{\\text{Baseline} \\\\ \\text{outcome} \\\\ \\text{at } t = 1}}} + \\color{black} \\sum_{\\tau = 1}^t  \\color{gray}{\\overbrace{\\color{black}{\\eta_t}}^{\\substack{\\text{Global} \\\\ \\text{time} \\\\ \\text{trend}}}} + \\color{gray}{\\overbrace{\\color{black}{\\delta}}^{\\substack{\\text{Homogenous} \\\\ \\text{treatment} \\\\ \\text{effect}}}} \\color{#A4BD0A}{D_{it}}\n$$\n\nThis all makes perfect sense is is nice and intuitive. It's how I typically generate fake data too (see the `outcome_baseline` up at the beginning of this post, for instance) and it's a neat way of thinking about the separate components of a data generating process.\n\nAccording to Jakiela, if the treatment effect $\\delta$ is truly homogenous over time and country, the residuals of the outcome (i.e. the residuals from a model like `lm(outcome ~ country + year)`, or $\\tilde{Y}_{it}$) should have a linear relationship to the residualized treatment (i.e. the residuals from a model like `lm(treatment ~ country + year)`, or $\\delta\\tilde{D}_{it}$).\n\nAgain, due to my non-econometricianness, this idea that $\\tilde{Y}_{it}$ should be related to $\\delta\\tilde{D}_{it}$ didn't click for me until I thought about this formula in more regression-y terms. Consider this pseudo-regression equation:\n\n$$\n\\overbrace{Y_{it}}^{\\text{Outcome}} = \\overbrace{\\alpha_i}^{\\text{Intercept}} + \\overbrace{\\beta_t}^{\\text{Slope / trend}} + \\overbrace{\\epsilon_{it}}^{\\text{Residuals}}\n$$\n\nHere, if we run a regression like `lm(outcome ~ country + year)`, the intercept $\\alpha_i$ is analogous to $\\mu_i$, the slope $\\beta_t$ is like $\\eta_t$, and whatever's leftover (i.e. $\\epsilon_{it}$, or the residualized outcome $\\tilde{Y}_{it}$) is similar to $\\delta D_{it}$. $\\delta D_{it}$ isn't the same as $\\delta \\tilde{D}_{it}$, but we can calculate the residualized treatment the same way by removing country and year effects (like `lm(treatment ~ country + year)`). Basically, by residualizing both the treatment and outcome, and thus removing country and time effects (or the baseline country effect $\\mu_i$ and the time trend $\\eta_t$) from each, the residuals that remain are related to $\\delta$.\n\nAs long as $\\delta$ is constant across time and country—or as long as the effect is homogenous—it should show up equally in the residuals for both the outcome and treatment for both treated and untreated observations. (I THINK! I'M NOT SURE ABOUT THIS)\n\nWe already calculated the treatment residuals (or $\\tilde{D}_{it}$) when we looked at treatment weights earlier, so now we just need to calculate the outcome residuals ($\\tilde{Y}_{it}$). We can then see if the relationship between $\\tilde{D}_{it}$ and $\\tilde{D}_{it}$ looks the same for treated and untreated observations—the slopes in the two groups should be statistically indistinguishable from each other.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Build models for the residualized outcomes\nout_resid_primary <- lm(primary ~ country + factor(year), data = fpe_primary)\nout_resid_secondary <- lm(secondary ~ country + factor(year), data = fpe_secondary)\n\n# Add residuals to data with weights\nfpe_primary_weights <- fpe_primary_weights %>%\n  mutate(out_resid = residuals(out_resid_primary))\n\nfpe_secondary_weights <- fpe_secondary_weights %>%\n  mutate(out_resid = residuals(out_resid_secondary))\n```\n:::\n\n\nWe can check the similarity of these slopes a couple different ways. First, let's plot the residuals:\n\n\n::: {.cell .column-page-inset-right layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nplot_out_trt_primary <- ggplot(fpe_primary_weights,\n                               aes(x = treatment_resid, y = out_resid, color = factor(treatment))) +\n  geom_point(size = 0.75, alpha = 0.5) +\n  geom_smooth(aes(linetype = \"Loess\"), method = \"loess\", size = 1, se = FALSE, alpha = 0.5) +\n  geom_smooth(aes(linetype = \"OLS\"), method = \"lm\", se = FALSE) +\n  scale_color_viridis_d(option = \"rocket\", begin = 0.2, end = 0.8,\n                        labels = c(\"Untreated\", \"Treated\")) +\n  scale_linetype_manual(values = c(\"OLS\" = \"solid\", \"Loess\" = \"21\"),\n                        guide = guide_legend(override.aes = list(color = \"grey30\"))) +\n  labs(x = \"Residualized treatment\", y = \"Residualized outcome\",\n       title = \"Primary school enrollment\", color = NULL, linetype = NULL) +\n  theme_clean() +\n  theme(legend.position = \"bottom\")\n\nplot_out_trt_secondary <- ggplot(fpe_secondary_weights,\n                                 aes(x = treatment_resid, y = out_resid, color = factor(treatment))) +\n  geom_point(size = 0.75, alpha = 0.5) +\n  geom_smooth(aes(linetype = \"Loess\"), method = \"loess\", size = 1, se = FALSE, alpha = 0.5) +\n  geom_smooth(aes(linetype = \"OLS\"), method = \"lm\", se = FALSE) +\n  scale_color_viridis_d(option = \"rocket\", begin = 0.2, end = 0.8,\n                        labels = c(\"Untreated\", \"Treated\")) +\n  scale_linetype_manual(values = c(\"OLS\" = \"solid\", \"Loess\" = \"21\"),\n                        guide = guide_legend(override.aes = list(color = \"grey30\"))) +\n  labs(x = \"Residualized treatment\", y = \"Residualized outcome\",\n       title = \"Secondary school enrollment\", color = NULL, linetype = NULL) +\n  theme_clean() +\n  theme(legend.position = \"bottom\")\n\nplot_out_trt_primary | plot_out_trt_secondary\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/show-outcome-trt-resid-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\nFor primary enrollment, the lines for treated and untreated observations look like they have similar slopes. When using Loess lines, the two groups don't align perfectly, and the relationship between residualized treatment and residualized outcome doesn't look perfectly linear. When secondary enrollment is the outcome, the lines for the treated and untreated groups seem to switch directions—the slope is negative for untreated observations but positive for treated. This is a bad sign for the homogeneity assumption.\n\nWe can statistically test if the slopes in two groups are the same or not by using an interaction term in a regression model:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncheck_slopes_primary <- lm(out_resid ~ treatment_resid * factor(treatment),\n                           data = fpe_primary_weights)\n\ncheck_slopes_secondary <- lm(out_resid ~ treatment_resid * factor(treatment),\n                           data = fpe_secondary_weights)\n\nmodelsummary(list(\"Primary enrollment\" = check_slopes_primary,\n                  \"Secondary enrollment\" = check_slopes_secondary),\n             coef_rename = c(\"treatment_resid\" = \"Residualized treatment\",\n                             \"factor(treatment)1\" = \"Treatment group\",\n                             \"treatment_resid:factor(treatment)1\" = \"Treatment group × residualized treatment\",\n                             \"(Intercept)\" = \"Intercept\"),\n             estimate = \"{estimate}\",\n             statistic = c(\"s.e. = {std.error}\", \"p = {p.value}\"),\n             gof_map = tribble(\n               ~raw, ~clean, ~fmt,\n               \"nobs\", \"N\", 0,\n               \"r.squared\", \"R²\", 3\n             ),\n             escape = FALSE, output = \"kableExtra\") %>%\n  kable_styling(htmltable_class = \"table table-sm\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table table-sm\" style=\"width: auto !important; margin-left: auto; margin-right: auto; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:center;\"> Primary enrollment </th>\n   <th style=\"text-align:center;\"> Secondary enrollment </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Intercept </td>\n   <td style=\"text-align:center;\"> 0.320 </td>\n   <td style=\"text-align:center;\"> −0.202 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> s.e. = 0.894 </td>\n   <td style=\"text-align:center;\"> s.e. = 0.276 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> p = 0.721 </td>\n   <td style=\"text-align:center;\"> p = 0.466 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Residualized treatment </td>\n   <td style=\"text-align:center;\"> 23.761 </td>\n   <td style=\"text-align:center;\"> −2.902 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> s.e. = 3.968 </td>\n   <td style=\"text-align:center;\"> s.e. = 1.357 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> p = \n   </td>\n<td style=\"text-align:center;\"> p = 0.033 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Treatment group </td>\n   <td style=\"text-align:center;\"> 0.341 </td>\n   <td style=\"text-align:center;\"> −0.189 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> s.e. = 1.506 </td>\n   <td style=\"text-align:center;\"> s.e. = 0.473 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> p = 0.821 </td>\n   <td style=\"text-align:center;\"> p = 0.690 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Treatment group × residualized treatment </td>\n   <td style=\"text-align:center;\"> −7.806 </td>\n   <td style=\"text-align:center;\"> 5.248 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> s.e. = 6.073 </td>\n   <td style=\"text-align:center;\"> s.e. = 1.993 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;box-shadow: 0px 1.5px\">  </td>\n   <td style=\"text-align:center;box-shadow: 0px 1.5px\"> p = 0.199 </td>\n   <td style=\"text-align:center;box-shadow: 0px 1.5px\"> p = 0.009 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> N </td>\n   <td style=\"text-align:center;\"> 490 </td>\n   <td style=\"text-align:center;\"> 369 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> R² </td>\n   <td style=\"text-align:center;\"> 0.114 </td>\n   <td style=\"text-align:center;\"> 0.019 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nThe coefficient for \"Treatment group × residualized treatment\" shows the change in slope between the two groups. For primary enrollment, being in the treatment group reduces the slope by 7.8 (so from 23.761 to 15.961), but the standard errors around that change are huge and the p-value is not significant (p = 0.199). For secondary enrollment, though, being in the treatment group increases the slope by 5.3 (from -2.9 to positive 2.4), and that change is statistically significant (p = 0.009). \n\nSo for primary enrollment, there's not enough evidence to reject the hypothesis that the slopes are the same (or the hypothesis that the effect is homogenous), so we'll treat the effect as homogenous. Yay! That means we don't need to worry so much about the negatively-weighted treated country-years. For secondary enrollment, though, there's pretty strong evidence that the slopes aren't the same, which means the treatment effect is likely heterogenous, which also means that the treated country-years with negative weights are biasing the results substantially and we should thus be worried.\n\nWhen there are heterogenous treatment effects, we don't need to give up! This is what @CallawaySantAnna:2020 and @SunAbraham:2020 show how to do in their papers (and see @BakerLarckerWang:2021 for a general overview of those approaches). If treatment effects are indeed homogenous, there's no need to turn to these fancier TWFE estimators—but if they are heterogenous, there are new tools that help.\n\n\n## Jakiela's robustness checks\n\nNow that we've run those two diagnostics (checked for negative weights in treated units and checked for treatment effect homogeneity), we can do some neat robustness checks to see how badly these negative weight issues bias the TWFE estimate.\n\nAs long as we assume that treatment effects are homogenous (remember that $\\delta$ in the equation above doesn't have subscripts for country or year), we can safely drop some observations from the data and still find the same result. We can also strategically drop observations to check if negative treatment weights influence the results. Jakiela presents three different robustness checks that all involve dropping different categories of observations:\n\n- Exclude later years\n- Limit how many post-treatment years are kept\n- Exclude individual countries\n\n### Exclude later years\n\nSince negative treatment weights for treated country-years are more likely to appear in later years in the data, we can drop those later years and see how the treatment effect changes. \n\nFor primary schools, if we cut the data off at 2000, the treatment effect is 31.8 instead of the 20.4 we've been seeing with the full data. That estimate is higher, but it also has wider errors. Both the coefficient and the errors shrink as we add more years to the data, and the estimate eventually settles on ≈20 by 2005, which is also when negatively weighted treated rows start appearing.\n\nFor secondary schools, the treatment effect hovers around 0 is never statistically significant regardless of the cutoff year.\n\n\n::: {.cell .column-page-inset-right layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\ndifferent_max_years_primary <- tibble(end_year = 2000:2015) %>%\n  # Nest a filtered dataset in a cell for each year\n  mutate(data = map(end_year, ~filter(fpe_primary, year <= .))) %>%\n  # Calculate the TWFE estimate for each dataset\n  mutate(model = map(data, ~lm_robust(primary ~ treatment,\n                                      fixed_effects = ~ country + year,\n                                      data = .,\n                                      clusters = country, se_type = \"stata\"))) %>%\n  # Extract a data frame of the results\n  mutate(tidied = map(model, ~tidy(., conf.int = TRUE))) %>%\n  # Calculate residuals and treatment weights\n  mutate(model_resid = map(data, ~lm(treatment ~ country + factor(year), data = .)),\n         treatment_resid = map(model_resid, ~residuals(.)),\n         treatment_weight = map(treatment_resid, ~ . / sum(.^2)))\n\n# Calculate how many treated observations have negative weights\nprop_negative_primary <- different_max_years_primary %>%\n  unnest(c(data, treatment_resid, treatment_weight)) %>%\n  group_by(end_year) %>%\n  summarize(n_treated_negative_weight = sum(treatment_weight < 0 & treatment == 1),\n            n_treated = sum(treatment == 1),\n            prop_treated_negative_weight = n_treated_negative_weight / n_treated) %>%\n  mutate(prop_nice = percent(prop_treated_negative_weight, accuracy = 1))\n\n# Extract tidied results for plotting\ncoefs_to_plot_primary <- different_max_years_primary %>%\n  unnest(tidied)\n\ndifferent_max_years_secondary <- tibble(end_year = 2000:2015) %>%\n  mutate(data = map(end_year, ~filter(fpe_secondary, year <= .))) %>%\n  mutate(model = map(data, ~lm_robust(secondary ~ treatment,\n                                      fixed_effects = ~ country + year,\n                                      data = .,\n                                      clusters = country, se_type = \"stata\"))) %>%\n  mutate(tidied = map(model, ~tidy(., conf.int = TRUE))) %>%\n  mutate(model_resid = map(data, ~lm(treatment ~ country + factor(year), data = .)),\n         treatment_resid = map(model_resid, ~residuals(.)),\n         treatment_weight = map(treatment_resid, ~ . / sum(.^2)))\n\nprop_negative_secondary <- different_max_years_secondary %>%\n  unnest(c(data, treatment_resid, treatment_weight)) %>%\n  group_by(end_year) %>%\n  summarize(n_treated_negative_weight = sum(treatment_weight < 0 & treatment == 1),\n            n_treated = sum(treatment == 1),\n            prop_treated_negative_weight = n_treated_negative_weight / n_treated) %>%\n  mutate(prop_nice = percent(prop_treated_negative_weight, accuracy = 1))\n\ncoefs_to_plot_secondary <- different_max_years_secondary %>%\n  unnest(tidied)\n\n# Coefficient plot\nate_primary <- ggplot(coefs_to_plot_primary, aes(x = end_year, y = estimate)) +\n  geom_hline(yintercept = 0, color = \"#FF2E00\", size = 1) +\n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high),\n                  color = \"#0599B0\", size = 1, fatten = 2) +\n  labs(x = NULL, y = \"TWFE-based treatment effect\",\n       title = \"Primary school enrollment\") +\n  theme_clean() +\n  theme(axis.title.x = element_blank(),\n        axis.text.x = element_blank())\n\nate_secondary <- ggplot(coefs_to_plot_secondary, aes(x = end_year, y = estimate)) +\n  geom_hline(yintercept = 0, color = \"#FF2E00\", size = 1) +\n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high),\n                  color = \"#0599B0\", size = 1, fatten = 2) +\n  labs(x = NULL, y = \"TWFE-based treatment effect\",\n       title = \"Secondary school enrollment\") +\n  theme_clean() +\n  theme(axis.title.x = element_blank(),\n        axis.text.x = element_blank())\n\n# Bar plot\nprop_neg_primary <- ggplot(filter(prop_negative_primary,\n                                  prop_treated_negative_weight > 0),\n                           aes(x = end_year, y = prop_treated_negative_weight)) +\n  geom_col(fill = \"#FF4136\") +\n  geom_text(aes(label = prop_nice),\n            nudge_y = 0.02, size = 2.5,\n            family = \"Barlow Semi Condensed Bold\", color = \"#FF4136\") +\n  coord_cartesian(xlim = c(2000, 2015)) +\n  labs(x = \"Last year included in data\", y = NULL,\n       subtitle = \"% of treated observations with negative weight\") +\n  theme_clean() +\n  theme(panel.grid.major.y = element_blank(),\n        axis.text.y = element_blank())\n\nprop_neg_secondary <- ggplot(filter(prop_negative_secondary,\n                                    prop_treated_negative_weight > 0),\n                             aes(x = end_year, y = prop_treated_negative_weight)) +\n  geom_col(fill = \"#FF4136\") +\n  geom_text(aes(label = prop_nice),\n            nudge_y = 0.02, size = 2.5,\n            family = \"Barlow Semi Condensed Bold\", color = \"#FF4136\") +\n  coord_cartesian(xlim = c(2000, 2015)) +\n  labs(x = \"Last year included in data\", y = NULL,\n       subtitle = \"% of treated observations with negative weight\") +\n  theme_clean() +\n  theme(panel.grid.major.y = element_blank(),\n        axis.text.y = element_blank())\n\n((ate_primary / prop_neg_primary) + plot_layout(heights = c(0.8, 0.2))) |\n  ((ate_secondary / prop_neg_secondary) + plot_layout(heights = c(0.8, 0.2)))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/robust-exclude-later-years-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n### Change how many post-treatment years are kept\n\nDropping rows based on end years like this is neat, but it doesn't take into account the differential treatment timing. Countries like Mozambique, which eliminated its fees in 2005, don't even show up in the first few models of exclude-later-years robustness check, since those models end in 2000–2004. As an alternative, we can keep specific numbers of years post-treatment for each country. For instance, we can look at Mozambique 2, 3, 4, or 5 (and so on) years after treatment. Doing this centers all countries at $t = 0$, rather than $t = \\text{start year}$.\n\nFor primary schools in this situation, the effect is smaller and not significant when only a few post-treatment years are kept, but it stabilizes at around 20 after only 5 post-treatment years, which suggests that $\\delta$ is indeed homogenous—we don't need a ton of post-treatment data to find it. For secondary schools, though, the effect remains negative and insigificant throughout every specification.\n\n\n::: {.cell .column-page-inset-right layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nfpe_primary_years_since <- fpe_primary %>%\n  mutate(years_after = year - fpe_year)\n\nfpe_secondary_years_since <- fpe_secondary %>%\n  mutate(years_after = year - fpe_year)\n\ndifferent_years_after_primary <- tibble(post_trt_years = 2:22) %>%\n  # Nest a filtered dataset in a cell for each year\n  mutate(data = map(post_trt_years, ~filter(fpe_primary_years_since, years_after <= .))) %>%\n  # Calculate the TWFE estimate for each dataset\n  mutate(model = map(data, ~lm_robust(primary ~ treatment,\n                                      fixed_effects = ~ country + year,\n                                      data = .,\n                                      clusters = country, se_type = \"stata\"))) %>%\n  # Extract a data frame of the results\n  mutate(tidied = map(model, ~tidy(., conf.int = TRUE))) %>%\n  # Calculate residuals and treatment weights\n  mutate(model_resid = map(data, ~lm(treatment ~ country + factor(year), data = .)),\n         treatment_resid = map(model_resid, ~residuals(.)),\n         treatment_weight = map(treatment_resid, ~ . / sum(.^2)))\n\n# Calculate how many treated observations have negative weights\nprop_negative_primary <- different_years_after_primary %>%\n  unnest(c(data, treatment_resid, treatment_weight)) %>%\n  group_by(post_trt_years) %>%\n  summarize(n_treated_negative_weight = sum(treatment_weight < 0 & treatment == 1),\n            n_treated = sum(treatment == 1),\n            prop_treated_negative_weight = n_treated_negative_weight / n_treated) %>%\n  mutate(prop_nice = percent(prop_treated_negative_weight, accuracy = 1))\n\n# Extract tidied results for plotting\ncoefs_to_plot_primary <- different_years_after_primary %>%\n  unnest(tidied)\n\ndifferent_years_after_secondary <- tibble(post_trt_years = 2:22) %>%\n  mutate(data = map(post_trt_years, ~filter(fpe_secondary_years_since, years_after <= .))) %>%\n  mutate(model = map(data, ~lm_robust(secondary ~ treatment,\n                                      fixed_effects = ~ country + year,\n                                      data = .,\n                                      clusters = country, se_type = \"stata\"))) %>%\n  mutate(tidied = map(model, ~tidy(., conf.int = TRUE))) %>%\n  mutate(model_resid = map(data, ~lm(treatment ~ country + factor(year), data = .)),\n         treatment_resid = map(model_resid, ~residuals(.)),\n         treatment_weight = map(treatment_resid, ~ . / sum(.^2)))\n\nprop_negative_secondary <- different_years_after_secondary %>%\n  unnest(c(data, treatment_resid, treatment_weight)) %>%\n  group_by(post_trt_years) %>%\n  summarize(n_treated_negative_weight = sum(treatment_weight < 0 & treatment == 1),\n            n_treated = sum(treatment == 1),\n            prop_treated_negative_weight = n_treated_negative_weight / n_treated) %>%\n  mutate(prop_nice = percent(prop_treated_negative_weight, accuracy = 1))\n\ncoefs_to_plot_secondary <- different_years_after_secondary %>%\n  unnest(tidied)\n\n# Coefficient plot\nate_primary <- ggplot(coefs_to_plot_primary, aes(x = post_trt_years, y = estimate)) +\n  geom_hline(yintercept = 0, color = \"#FF2E00\", size = 1) +\n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high),\n                  color = \"#0599B0\", size = 1, fatten = 2) +\n  labs(x = NULL, y = \"TWFE-based treatment effect\",\n       title = \"Primary school enrollment\") +\n  theme_clean() +\n  theme(axis.title.x = element_blank(),\n        axis.text.x = element_blank())\n\nate_secondary <- ggplot(coefs_to_plot_secondary, aes(x = post_trt_years, y = estimate)) +\n  geom_hline(yintercept = 0, color = \"#FF2E00\", size = 1) +\n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high),\n                  color = \"#0599B0\", size = 1, fatten = 2) +\n  labs(x = NULL, y = \"TWFE-based treatment effect\",\n       title = \"Secondary school enrollment\") +\n  theme_clean() +\n  theme(axis.title.x = element_blank(),\n        axis.text.x = element_blank())\n\n# Bar plot\nprop_neg_primary <- ggplot(filter(prop_negative_primary,\n                                  prop_treated_negative_weight > 0),\n                           aes(x = post_trt_years, y = prop_treated_negative_weight)) +\n  geom_col(fill = \"#FF4136\") +\n  geom_text(aes(label = prop_nice),\n            nudge_y = 0.02, size = 2.5,\n            family = \"Barlow Semi Condensed Bold\", color = \"#FF4136\") +\n  coord_cartesian(xlim = c(2, 22)) +\n  labs(x = \"Post-treatment years included\", y = NULL,\n       subtitle = \"% of treated observations with negative weight\") +\n  theme_clean() +\n  theme(panel.grid.major.y = element_blank(),\n        axis.text.y = element_blank())\n\nprop_neg_secondary <- ggplot(filter(prop_negative_secondary,\n                                    prop_treated_negative_weight > 0),\n                             aes(x = post_trt_years, y = prop_treated_negative_weight)) +\n  geom_col(fill = \"#FF4136\") +\n  geom_text(aes(label = prop_nice),\n            nudge_y = 0.02, size = 2.5,\n            family = \"Barlow Semi Condensed Bold\", color = \"#FF4136\") +\n  coord_cartesian(xlim = c(2, 22)) +\n  labs(x = \"Last year included in data\", y = NULL,\n       subtitle = \"% of treated observations with negative weight\") +\n  theme_clean() +\n  theme(panel.grid.major.y = element_blank(),\n        axis.text.y = element_blank())\n\n((ate_primary / prop_neg_primary) + plot_layout(heights = c(0.8, 0.2))) |\n  ((ate_secondary / prop_neg_secondary) + plot_layout(heights = c(0.8, 0.2)))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/robust-post-treatment-years-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n### Exclude individual countries\n\nFinally, since early adopter countries are more likely to have negative treatment weights, we can remove individual countries from the panel to see what their omission does to the overall TWFE estimate. For primary school enrollment, the ATE remains positive and significant across most specifications, except when Malawi, Uganda, or Namibia are excluded. But Malawi and Uganda were early adopters and thus have negatively weighted treatment observations in later years, as we saw earlier, which give them strange leverage in the the overall TWFE ATE calculation. For secondary schools, the effect remains basically zero and insignificant across all specifications except when Malawi is omitted, but that's again because Malawi was an early adopter.\n\n\n::: {.cell .column-page-inset-right layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nfpe_omit_countries_primary <- fpe_primary %>%\n  arrange(fpe_year, country) %>%\n  mutate(country_start = paste0(country, \" (\", fpe_year, \")\"),\n         country_start = fct_inorder(country_start)) %>%\n  distinct(country, country_start) %>%\n  mutate(data = map(country, ~filter(fpe_primary, country != .))) %>%\n  mutate(model = map(data, ~lm_robust(primary ~ treatment,\n                                      fixed_effects = ~ country + year,\n                                      data = .,\n                                      clusters = country, se_type = \"stata\"))) %>%\n  mutate(tidied = map(model, ~tidy(., conf.int = TRUE)))\n\ncoefs_to_plot_primary <- fpe_omit_countries_primary %>%\n  unnest(tidied)\n\nfpe_omit_countries_secondary <- fpe_secondary %>%\n  arrange(fpe_year, country) %>%\n  mutate(country_start = paste0(country, \" (\", fpe_year, \")\"),\n         country_start = fct_inorder(country_start)) %>%\n  distinct(country, country_start)  %>%\n  mutate(data = map(country, ~filter(fpe_secondary, country != .))) %>%\n  mutate(model = map(data, ~lm_robust(secondary ~ treatment,\n                                      fixed_effects = ~ country + year,\n                                      data = .,\n                                      clusters = country, se_type = \"stata\"))) %>%\n  mutate(tidied = map(model, ~tidy(., conf.int = TRUE)))\n\ncoefs_to_plot_secondary <- fpe_omit_countries_secondary %>%\n  unnest(tidied)\n\nate_primary <- ggplot(coefs_to_plot_primary, aes(x = estimate, y = fct_rev(country_start))) +\n  geom_vline(xintercept = 0, color = \"#FF2E00\", size = 1) +\n  geom_pointrange(aes(xmin = conf.low, xmax = conf.high),\n                  color = \"#0599B0\", size = 1, fatten = 2) +\n  labs(x = \"TWFE-based treatment effect\", y = NULL,\n       title = \"Primary school enrollment\",\n       subtitle = \"Each point represents the ATE when omitting the specified country\",\n       caption = \"Year that fees were eliminated is shown in parentheses\") +\n  coord_cartesian(xlim = c(-10, 50)) +\n  theme_clean() +\n  theme(panel.grid.major.y = element_blank())\n\nate_secondary <- ggplot(coefs_to_plot_secondary, aes(x = estimate, y = fct_rev(country_start))) +\n  geom_vline(xintercept = 0, color = \"#FF2E00\", size = 1) +\n  geom_pointrange(aes(xmin = conf.low, xmax = conf.high),\n                  color = \"#0599B0\", size = 1, fatten = 2) +\n  labs(x = \"TWFE-based treatment effect\", y = NULL,\n       title = \"Secondary school enrollment\") +\n  coord_cartesian(xlim = c(-10, 50)) +\n  theme_clean() +\n  theme(panel.grid.major.y = element_blank())\n\nate_primary | ate_secondary\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/robust-drop-countries-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n## tl;dr: Conclusion\n\n***Phew.*** That was a ton of code, but coding my way through this paper and translating Jakiela's diagnostics and robustness checks from math into R was incredibly helpful for me to start understanding all this new TWFE stuff.\n\nHere are the main tl;dr takeaways from her paper:\n\n- We can think of OLS as a weighted sum of outcome values - these weights are typically negative for untreated observations and positive for treated observations\n- In TWFE situations, these weights take country and year into account\n- Because of mathy reasons, treated observations can actually get negative weights—especially countries that are early adopters, and country-year observations in later years\n- We can see if these negative weights on treated observations are an issue by using a couple simple diagnostics: see how many and which treated observations have negative weights, and see if the treatment effect is homogenous across treated countries\n- We can look at which treated observations have negative weights by making some plots and exploring the data\n- We can check for the homogeniety of the treatment effect by running a regression that uses the residualized treatment and treatment status to\nexplain the residualized outcome. If the slopes for treated and comparison observations are indistinguishable, we can safely assume treatment homogeneity.\n- Finally, we can check how robust the TWFE estimate is to negative treatment weights and the assumption of homogeneity by dropping specific types of observations and checking the ATE across these modified datasets\n\n\n## References\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../../../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../../../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}